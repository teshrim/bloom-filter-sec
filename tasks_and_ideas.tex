\section{Tasks, and Ideas for Tasks}

\heading{Theory tasks.}
\begin{itemize}
\item Prove that a Bloom filter using hash functions defined by $h_j(x) = \left( f_{K0}(x) + j\cdot g_{K1}(x)\right) \bmod m$, for secret keys $K0,K1$, is FP-secure when either~$f$ or~$g$ is a secure PRF.  (This is a real proposal, see the intro.)  Interesting that these $h_j$ are not independent, even if $f_{K0},g_{K1}$ are replaced by independent random functions, whereas the traditional BF false positive analysis treats the $h_j$ as independent.  I wonder if the analysis for determining the number of hash functions still holds when the $h_j$ are dependent?  Note: definitely not in general, just consider $h_j$ a fixed function for all $j$; but it's an interesting question to ask for this particular kind of dependence.  (Should check the Kirsh, Mitzenmacher paper first; they probably address this. \tsnote{They show that two random functions, combined in this way (for a prime~$m$), suffices.  No increase in asymptotic FP probability.  They also argue that construction of $h_j$ is thus better than one can do using generic pairwise-independent $h_j$.  They also point out the difference between the FP \emph{probability} (the probability that a particular $x \not\in S$ causes a FP) and the FP \emph{rate} (the average FP probability over $x \not\in S$), which I hadn't really considered before. }) 

\item Show the same thing for the simpler $h_j(x) = f_{K}(\langle j \rangle \concat x) \bmod m$.  This, by the way, does give independent $h_j$ when you replace~$f_K$ by a random function.  (The previous ``double hashing'' construction seems clunky if you're going to assume you have a PRF and secret keys; is this just an example of people in one domain naively using a tool developed for another? )

\item  If I recall properly, a Bloom filter leaks the number of elements that it represents, if you know the filter size and the number of hash functions.  Verify this.  \tsnote{Approximately true.  If the distribution of the expected number of zero bits is tight around its mean, then you can use the actual number of 0-bits as the expected number, and then deduce the size of the set.}  Also, what about set-intersection attacks on Bloom filters?
\item This raises the more general question of schemes/protocols that use multiple Bloom filters to represent a single set based on distinct features of set elements.  We should dig into this.

\item Considering the P2P setting, how should we formalize insider attacks?  I'm thinking something like FP and privacy with corruptions.  What about authenticity of published Bloom filters?

\item Formalize ``unlinkability'', i.e. given some initial information about two representations $M_0,M_1$ before an element~$x$ is added, an adversary can't distinguish between $M_0 \cup x$ and $M_1 \cup x$ (abusing notation).  \tsnote{This is somewhat defined in Kerschbaum.}

\item Formalize a security goal for Stochastic Fair Blue (or similar TCP stream routing primitives) and prove that a secure, mutable hash-based filter implies secure Stochastic Fair Blue.

\item Do the same for other applications of Bloom-filter-like primitives.  (For example, attenuated Bloom filters, used in the OceanStore project (at least).)

\item Would a secure Bloom filter (of some kind) give us a secure strike list (whatever secure means), like what was originally proposed in QUIC?  Are Bloom filters used in edge network servers for big providers like Facebook, LinkedIn, Google, etc.?
\end{itemize}

\heading{Systems-y tasks.}
\begin{itemize}
\item Find measurement info on false positive rates for Squid filters/HTTP proxies in practice.  This must have been done already.

\item Break a Squid server!  I'm thinking about a privacy break here.  One could start by simulating the (very simple) Bloom filter that Squid implements, and eventually stand up an actual Squid proxy.  Perhaps populate the filter with a random sampling of URLs from the Alexa top 1000.  (How large a sample?)  Given access to the filter, we can probably use the same attacks leveraged by Niedermayer et al.\ to infer information about which URLs are cached.  Of course, there's a timing based attack, just pinging the Squid proxy with URLs.   But this is probably harder than it sounds, and I don't know if/how Squid updates its filter on false-positive/cache misses. \tsnote{Apparently Crosby and Wallach gives some attacks.} \tsnote{Gerbet et al. give some generic attacks that are interesting.  I wonder if Squid, because it uses MD5, admits faster ``pollution attacks'' on the filter, e.g. where the adversary finds URLs that would set far more bits to 1 than one would expect? (Yep, see Crosby and Wallach.)}

\item Fix a Squid server!  Implement a fix that is \emph{fast} and doesn't suffer from deployment headaches at interesting scales.  If the attack is bad enough, and the fix is efficient enough, we might even get this pushed into the Squid codebase. \tsnote{Not surprisingly, people have addressed this.  See the related work section in the intro.  Need to review what's been done, what has proofs, etc.}

\item What about breaking, via a real attack that we implement, things like HBase that use non-cryptographic hash functions?  (HBase apparently uses the Murmur hash.)  If there's a really damaging attack, and a plausible opportunity for someone to mount it, then that would be pretty slashy.

\item Speaking of the Niedermayer et al. attacks, these exploit the fact that there are different bloom filters for different record identifiers (i.e. one for last name, one for first name, one for city, etc.).  They propose various way to render their attacks useless, or at least very inefficient.  Can we actually prove something about one or more of the proposed countermeasures?  

\item What about content-based routing (or whatever they are calling that area now)?  A Bloom filter seems like an obvious tool for that setting, and the content-seeker might want to keep its preferences private.

\item What about Google's BigTable or HBase?  What is the security threat there?

\item Generally speaking, can we characterize operational settings in a way that surfaces an interesting security/performance trade-off?  For example, the Bloom filters used by Akamai's CDN are on the order of 600-700MB in size and are shared among several machines in a local area.  The Bloom filters used in a simple spam-detection system (do these exist) are likely to be much smaller, maintained locally on a single machine, and much easier to update.  Solutions in one setting are not going to be useful in another.  Likewise, attacks in one setting may not scale to another, e.g. the preimage-finding/polluting-point attacks in that INRIA whitepaper.

\end{itemize}