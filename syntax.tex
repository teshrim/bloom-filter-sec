\newcommand{\qry}{\mathsf{qry}}
\section{(Multiset) Data Structures}

\jnote{Make more general.}

\heading{Preliminaries. } When~$\univ$ is a set and $n>0$ is an
integer, we let $[\univ]^n$ denote the set of all size-$n$ subsets
of~$\univ$, and $[[\univ]]^n$ for the set of all multisets
over~$\univ$ with total multiplicity~$n$. \jnote{I guess we are
viewing sets as a special case of multisets, so maybe just say
that.}  We write $x \getsr \univ$ to denote
sampling an element uniformly from~$\univ$ and assigning it to~$x$,
and we extend this notation to randomized algorithms. When~$X$ is a
string over some alphabet~$\Sigma$, we write $|X|$ for the bitlength
of~$X$, relative to some fixed encoding.  When~$X$ is a multiset, we
overload the notation so that~$|X|$ is the total multiplicity
of~$X$.

Algorithms may be provided black-box access to one or more oracles,
which we write as superscripts, e.g., $F^{O_1,O_2,\ldots}$.  An \emph{adversary} is a randomized algorithm.

\heading{Data structures.}  We begin by defining a general primitive
that produces a representation of a given multiset, and provides a
mechanism to answer a specified collection of questions about that
multiset. \jnote{I still think we should be more general, and deal
with objects other than multisets. Actually, I think we should
either specialize to sets or talk generically about data structures
for arbitrary objects; talking about multisets seems to make the
definitions more cumbersome while not adding very much in terms of
generality.}
%Informally, the representation should serve as a good
%approximation of the multiset, at least with respect to the allowed queries.
\begin{definition}[Data structure] \rm
Fix a non-empty set~$\univ$, and a collection of (multi)sets~$\calS$
over $\univ$. A \emph{data structure} (for $\calS$) is a tuple
$\setprim=(\calQ,\Rep, \Qry)$ where \jnote{I would prefer moving
$\calQ$ out of the tuple, and instead calling it a ``data structure
for $\calQ$ over $\calS$.''}\tsnote{But $\Qry$ really is tied to
$\calQ$, as those are the only queries upon which $\Qry$ is defined to
operate.  So, if anything, I would support removing $\calQ$ from the
high-level API, and just explaining what it is as part of the
description of $\Qry$}:
\begin{itemize}
\item $\mathcal{Q}=\{\qry \colon \mathcal{S} \to \Gamma\}$ is a set
    of supported \emph{queries}, where $\Gamma$ is the set of query \emph{answers}.
\item $\Rep \colon \mathcal{S} \to \bits^*
    \times \bits^*$ is a randomized \emph{representation
    algorithm}, taking as input a (multi)set $S \in \mathcal{S}$, and outputting %a \emph{representation} $M \in \Sigma^*$,
    \emph{public representation data} $\pubaux \in \bits^*$ and
    \emph{private representation data} $\privaux \in \bits^*$. We write
    $(\pubaux,\privaux) \getsr \Rep(S)$ as shorthand for this execution.
\item $\Qry\colon \bits^* \times \bits^* \times \calQ \to
    \Gamma$ is a deterministic \emph{query-evaluation}
    algorithm, taking as input $\pubaux,\privaux \in \bits^*$
    and a query $\qry \in \calQ$, and outputting an \emph{answer}
    $a \in \Gamma$.  We write $a \gets \Qry(\pubaux,\privaux,\qry)$
    for this execution.
\end{itemize}
\hfill\dqed
\end{definition}

\todo{Insert discussion of syntax, if needed.  If we think it is
  helpful to discuss the size of the representation, we can declare it
as $|\pubaux|+|\privaux|$ and comment that if one wants to compare to
classical size bounds, a more fine-grained separation of the output of
$\Rep$ would allow this.}


\begin{definition}[Error probability and rate] \rm
For a given data structure $\setprim=(\calQ,\Rep, \Qry)$, let
$\mathrm{Err}(S,\qry,\pubaux,\privaux)$ be a predicate that is true iff
$\Qry(\pubaux,\privaux, \qry) \neq \qry(S)$.  Then $\Pi$ has \emph{error
probability} $\epsilon$ if $\max_{S,\qry}\Pr[(\pubaux,\privaux) \getsr
\Rep(S) : \mathrm{Err}(S,\qry,\pubaux,\privaux)=1 ] \leq \epsilon$.
%
It has \emph{error rate} $\tilde{\epsilon}$ if
$\max_{S}\Pr[(\pubaux,\privaux) \getsr \Rep(S);\, \qry \getsr \calQ :
\mathrm{Err}(S,\qry,\pubaux,\privaux)=1] \leq \tilde{\epsilon}$. \hfill\dqed
\end{definition}

%We will sometimes say that a data structure is
%$(1-\epsilon)$-correct, meaning it has error probability~$\epsilon$.
%Note that $1-\epsilon$ is a worst-case lower bound on the
%correctness of the data structure. \tsnote{Don't know if this will be necessary.}

These definitions, and those that follow, can be lifted to the random-oracle
model by giving $\Rep, \Qry$ access to a random oracle. In that
case, the probabilities defining the error probability and error
rate are also taken over choice of the random oracle.

We note that, while our error probability and error rate do not
distinguish among ``types'' of errors, they also do not preclude
instantiations (like the classical Bloom filter) that admit only one
type of error, e.g., false positives.


\def\bin{{\sf Bin}}
\heading{Error probability vs.\ error rate. }
We pause to highlight an important
difference between error probability and error rate.  In particular,
the error probability~$\epsilon$ is measured only over the coins
of~$\Rep$, for a fixed~$S$ and query~$\qry$. Once the coins of~$\Rep$
are fixed, it is not straightforward how to connect~$\epsilon$ to
events that depend on other sources of randomness.   We illustrate how
this surfaces with the following example.

Let~$\Pi$ be a data structure that has error-probability $\epsilon$,
and consider a correctness-violating attack that asks random
queries $\qry_1,\qry_2,\ldots,\qry_T$, i.e., uniform samples from~$\calQ$.
Let $\mathrm{Err}_i$ be a random variable indicating the event
$\Qry(\pubaux,\privaux,\qry_i)\neq \qry_i(S)$.  We know that the probability
that $\mathrm{Err}_i=1$ is at most~$\epsilon$, and it is tempting to
model the~$\mathrm{Err}_i$ as i.i.d. Bernoulli trials with success
probability~$\epsilon$. However, a moment's reflection shows that
this is not the case.  Concretely, consider the following scheme.
Fix $|S|=n$ for all $S \in \calS$, where $n \ll |\univ|$. For the
queries, let $\calQ = \{\qry_x\colon \calS \to \bits \,|\, \forall x
\in \univ\}$ where $\forall S \in \calS$ the predicate $\qry_x(S)=1
\Leftrightarrow x \in S$.  Let $\Rep(S)$ pick a random element~$s
\in S$, and return $M = S \setminus \{s\}$ and $\privaux =
\emptystring$.  To respond to queries,
let~$\Qry(\pubaux,\privaux,\qry_x)=1$ iff $x \in M$.  It is easy to see
that this scheme is $1/n$-correct; for any fixed~$S$, there are
exactly~$n$ queries~$\qry_x$ that have probability~$1/n$  (over the
coins of~$\Rep$) of causing a correctness error, and the remaining
$|\univ|-n$ queries have probability zero of causing an error.
Moreover, once the coins of~$\Rep$ are fixed, there is exactly
\emph{one} query that will cause an error.  Thus for random queries
from~$Q$, for all~$i\in[T]$ we have
$\Prob{\mathrm{Err}_i=1}=1/|\univ| \ll 1/n = \epsilon$.


\heading{Data structures for set-multiplicity queries.} Our
particular focus will be on data structures that support
multiplicity queries.

\begin{definition} \rm
A \emph{set-multiplicity data structure} is a data structure with
$\Gamma=\mathbb{N}$ and $\calQ=\{\qry_x\}_{x \in \univ}$, where
$\qry_x(S)$ is defined to be the multiplicity of~$x$ in the
multiset~$S$. \hfill\dqed
\end{definition}

\jnote{Clean up the following, because we discuss BFs later.}

The classical Bloom filter is a special case of a set-multiplicity
data structure, as set-membership queries are a type of
set-multiplicity query.  Specifically,
%\jnote{Only handles sets, not multisets.}
let $\Gamma=\bits$, and fix functions $k(\cdot)$ and $m(\cdot)$
parameterizing the scheme.  Algorithm $\Rep$, on input a set~$S$,
computes $k=k(|S|)$ and $m=m(|S|)$ and then chooses $k$ functions
$h_1, \ldots, h_k \in \mathcal{H}$ for some function family
$\mathcal{H}=\{h \colon \univ \to \mathbb{N}\}$.\footnote{For this
  example, we are implicitly assuming that the range of the hash
  functions admits a natural mapping to $[m]$.  In practice, this
  could be enforced in various ways, including allowing $\Rep$ to
  return an indication of error. }
It then computes an $m$-bit
array~$M$ (initialized to 0 everywhere) by setting $M[h_i(x)]=1$ for
all $i\in [k]$ and $x \in S$.  Finally, $\Rep$ returns
$\privaux=\emptystring$ and $\pubaux = \langle
M,h_1,h_2,\ldots,h_k\rangle$ as the representation.
%
Algorithm~$\Qry$ is defined so that, on input
$(\pubaux,\privaux,\qry_x)$, it returns the minimum of the values
$M[h_1(x)],\ldots,M[h_k(x)]$.  We note that the standard Bloom filter
analysis treats $h_1,h_2,\ldots,h_k$ as independent random functions,
which we may capture in the ROM with some simple adjustments to the above.

As a simple extension, consider $\Gamma=\mathbb{N}$ and modify the
classical Bloom filter so that it stores counters, rather than bits, at
each position in an array.  In particular, for each~$x \in S$ the
$\Rep$~algorithm increments the counters stored at positions
$h_1(x), h_2(x), \ldots, h_k(x)$, returns the final array of
counters as~$M$.  The $\Qry$-algorithm remains the same. Such a
construction gives a static version of a counting Bloom
filter~\cite{fan2000summary}.  We will capture dynamic versions, as well as
count-min sketches~\cite{cormode2005improved}, scalable Bloom filters~\cite{almeida2007scalable},
etc., in future work.\tsnote{?}

A Bloom filter with secret hash functions is captured by setting
$\privaux=(h_1,h_2,\ldots,h_k)$, and setting $\pubaux=M$.
Related constructions that use a secret key~$K$, but not for hashing (e.g.\ the PRP-based
construction from NY), are captured setting $\privaux=K, \pubaux=M$.

\tsnote{needs updating, since $\Sigma$ is gone, and the range of
  $\Rep$ is just $\bits^*$ with implicit encoding of whatever is the
  ``natural'' way to think about $\pubaux$ (e.g. counters, xor-shares)}
By setting $\Sigma=\bits^L$ for a specified $L>0$, we can capture
the so-called ``garbled Bloom filter'' due to Dong, Chen and
Wen~\cite{dong2013private}. \todo{Details have to be filled in.} This stores
xor-shares of bitstring~$x \in S$ at positions
$h_1(x),h_2(x),\ldots,h_k(x)$ in an array. Similarly, the
cuckoo-hashing construction from NY, which (loosely speaking) stores
a hash $g(x)$ at positions determined by
$h_1(x),h_2(x),\ldots,h_k(x)$, is captured when $L=|g(x)|$.
\todo{Check the correctness of this claim.}
