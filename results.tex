\section{Achieving Security Notions}

\subsection{A Meta-Theorem for Privacy}
Here we prove a result that can be used to show that a large class of ``canonical''
data structures are semantically secure, with respect to leakage of the size of the set.
\jnote{It would not be too hard to generalize this to arbitrary data structures over
arbitrary objects, so long as the number of distinct queries to the PRF made by $\Rep$
depends only on ${\sf leak}$.}

We first define what we mean by ``canonical.''

\def\bits{\{0,1\}}

\begin{definition}
A set-multiplicity data structure $(\Rep, \Qry)$ is {\sf canonical} if
there exist algorithms $\Rep_1, \Rep_2$, and a function
$F: \calK \times \bits^{\ell_{in}} \rightarrow \bits^{\ell_{out}}$
such that the following hold:
\begin{itemize}
\item $\Rep_1$ takes as input a set $S=\{x_1,\ldots,x_n\}$ and outputs distinct values $s_1, \ldots, s_t \in \bits^{\ell_{in}}$,
where $t$ depends only on~$n$.
\item $\Rep_2$ takes as input $n$ and $y_1, \ldots, y_t \in \bits^{\ell_{out}}$, and outputs
$\pubaux$.
\item For any $S$, the distribution on $\pubaux$ output by $\Rep(S)$ is identical to the distribution
on $\pubaux$ computing as follows:
\begin{enumerate}
\item $s_1, \ldots, s_t \getsr \Rep_1(S)$;
\item $K \getsr \calK$ for some fixed number of keys~$p$;
\item $\pubaux \getsr \Rep_2(n, F_{K}(s_1), \ldots,F_{K}(s_t))$. 
%\item $K_1,K_2,\ldots,K_p \getsr \calK$ for some fixed number of keys~$p$;
%\item $\pubaux \getsr \Rep_2(n, \{F_{K_j}(s_1), \ldots,F_{K_j}(s_t)\}_{j\in[p]})$. 
\end{enumerate}
\end{itemize}
In this case, we say that $(\Rep_1, \Rep_2, F)$ is the {\sf canonical representation}
of~$\Rep$. \tsnote{Seems odd to call it this without explaining how
  this canonical representation handles $\privaux$, too.  }
\end{definition}
\jnote{Not sure how general to make the above. Need to verify that it is general enough
to prove security of all the constructions we care about.}
\tsnote{Would be good to give an example or two of the schemes this
  covers.  Domain-separated PRF BF, for example.  I think it covers
  classical BF, too, if $F_K(s)=s$ for all $K \in \calK$, $\Rep_1$
  simply returns the elements of~$S$, and $\Rep_2$ actually picks hash
  functions and does the hashing. (Although the following theorem does
  not work in this case, of course.) It does not cover
  linear-PRF or Neidermayer. }
We next show that any canonical data structure in which~$F$ is a pseudorandom function is
semantically secure with respect to leakage consisting of the size of the set.

\begin{theorem}
Let $\Pi=(\Rep, \Qry)$ be a canonical set-multiplicity data structure for which $\Rep$ has canonical representation
$(\Rep_1, \Rep_2, F)$. If $F$ is a $(t, \epsilon)$-pseudorandom
function \tsnote{overloading~$t$}, then $\Pi$ is semantically secure
with respect to leakage function ${\sf leak}(S) = |S|$.
\tsnote{We have a mixture of styles of theorem statements, resource-parameterized statements vs.\ ``verbose'' concrete statements.  We
  need to make things uniform.}
\end{theorem}
\begin{proof}
We define the following simulator $\Sim$: on input $n$, define $S^*=\{e_1, \ldots, e_n\}$
(for distinct elements $e_1, \ldots, e_n$). Then compute
\begin{enumerate}
\item $s_1, \ldots, s_t \getsr \Rep_1(S^*)$,
\item $K \getsr \calK$,
\item $\pubaux \getsr \Rep_2(|S|, F_K(s_1), \ldots, F_K(s_t))$,
\end{enumerate}
and output $\pubaux$.

\def\hyb{\mbox{{\sc Hyb}}}

For a given set $S$, define distribution $\mbox{{\sc Real}}_S$ as
\[ \{ (\pubaux, \privaux) \getsr \Rep(S) : \pubaux\},\]
and define distribution $\mbox{{\sf Ideal}}_S$ as
\[ \{ \pubaux \getsr \Sim(|S|) : \pubaux \}.\]
Our goal is to show that $\mbox{{\sc Real}}_S$ and $\mbox{{\sf Ideal}}_S$ are computationally
indistinguishable for any set~$S$. \jnote{I'm not quite sure how to elegantly do a proof
like this in the concrete setting.}\tsnote{I think you just follow the
sketch that I typeset for the Domain-Separated PRF scheme. (I'll embed
notes below, too.) The bound will be exactly what is there, shoudl be able to just cut-and-paste,
basically.  All that's needed, I think, is to do resource accounting
for $\Sim$ and the PRF-adversary~$B$.}
To do so, first note that we can express $\mbox{{\sc Real}}_S$ as the outcome of
the following experiment: \tsnote{I'd call this ``Game $G0$''...}
\begin{enumerate}
\item $s_1, \ldots, s_t \getsr \Rep_1(S)$.
\item $K \getsr \bits^n$.
\item $\pubaux \getsr \Rep_2(|S|, F_k(s_1), \ldots, F_k(s_t))$.
\item Return $\pubaux$.
\end{enumerate}

Now, consider a hybrid distribution $\hyb_S$ computed as follows:
\tsnote{...and this ``Game $G1$''...}
\begin{enumerate}
\item $s_1, \ldots, s_t \getsr \Rep_1(S)$.
\item $y_1, \ldots, y_t \leftarrow \bits^{\ell_{out}}$
\item $\pubaux \getsr \Rep_2(|S|, y_1, \ldots, y_t)$.
\item Return $\pubaux$.
\end{enumerate}
It follows immediately from the fact that $F$ is a pseudorandom function (and efficiency
of $\Rep_2$) that $\hyb_S$ is computationally indistinguishable from $\mbox{{\sc Real}}_S$.
\tsnote{...and then it's clear that the difference between the
  probability of $G0 \outputs 1$ and $G1 \outputs 1$ is exactly the
  PRF advantage of~$B$, who simply uses it's oracle to simulate calls
  to $F_K$ prior to running $\Rep_2$...}
Next, consider the following distribution $\hyb'_S$:
\begin{enumerate}
\item $S^* := \{e_1, \ldots, e_n\}$, where $n = |S|$.
\item $s_1, \ldots, s_{t^*} \getsr \Rep_1(S^*)$.
\item $y_1, \ldots, y_{t^*} \leftarrow \bits^{\ell_{out}}$
\item $\pubaux \getsr \Rep_2(|S|, y_1, \ldots, y_{t^*})$.
\item Return $\pubaux$.
\end{enumerate}
We claim that $\hyb'_S$ is identically distributed to $\hyb_S$. The follows immediately from the
observation that the distribution on $t$ (in $\hyb_S$) is identical to the distribution on~$t^*$
(in $\hyb'_S$) by definition
of what it means to be canonical.
\tsnote{...and it is clear that the distriubtion of everything is the
  same as in Game $G1$, so we are done. }

To complete the proof, we simply note that $\hyb'_S$ and $\mbox{{\sf Ideal}}_S$
are computationally indistinguishable, again relying on pseudorandomness of~$F$.
\end{proof}

%Here is a proof sketch:
%The simulator, given n=|S|, runs the honest scheme on inputs x_1, ...,
%x_n and outputs the public portion of the result.
%
%To see that this is indistinguishable from the real public portion on
%the actual set S, consider the following hybrids:
%H0: The real pub produced from the real set S={s_1, ..., s_n}
%H1: Run the representation algorithm on S, but using random functions
%in place of PRFs, and output pub.
%H2: Run the representation algorithm on {x_1, ..., x_n}, still using
%random functions in place of PRFs, and output pub. The claim is that
%this is identically distributed to H1. The main observation is that
%since we are using random functions, the inputs to the random
%functions don't matter, subject to the technical condition that the
%number of distinct inputs to the random functions does not change.
%(Here is where we rely on the fact that |S|=n is known, as well as an
%appropriate definition of "natural.")
%H3: Run the representation algorithm on {x_1, ..., x_n}, using the
%real Rep (with PRFs).

%\jnote{Organize by scheme, not by security notions.}

\include{scheme-descriptions}


%%%%%%%%%%%%%%%%% LINEAR-PRF %%%%%%%%%%%%%%%%%%%%

\heading{Linear-PRF construction. }
Here we consider a set-multiplicity data structure that was attacked
by Neidermayer et al. in~\cite{xxx}. \todo{Not actually a true
  statement, because $\Rep$ isn't correct.  Needs fixing.} Fix $n,k,m \geq 0$ and let $\mathcal{S}=[\univ]^n$.  Then $\Pi_{\mathrm{lin}}= (\calQ,\Rep, \Qry)$ is defined as in Figure~\ref{fig:lin-and-ds} (left side).  The following result shows, informally, that if~$F$ is a good PRF, then $\Pi_\mathrm{lin}$ is correct against adaptive error-finding adversaries.

\begin{theorem}\label{thm1}\label{thm:lin-correctness}
Fix $k,m,n,r>0$, and let $\Pi_{\mathrm{lin}}= (\calQ,\Rep, \Qry)$ be the set-multiplicity data structure described in Figure~\ref{fig:lin-and-ds}. Let $\distr{}{}$ be a distribution over~$\mathcal{S}$.  For any adversary~$A$ that makes a total of~$q$ queries to its oracle and has time-complexity~$O(t)$, there exist prf-adversaries~$B_1,B_2$ (explicitly constructed in the proof of this theorem) such that
\[
\AdvCorrect{\Pi_{\mathrm{lin}},\distr{}{},r}{A} \leq  \AdvPRF{F}{B_1} + \AdvPRF{F}{B_2}  +{\dbinom{q}{r}} \left( (1-e^{-kn/m})^k + O(1/n) \right)^r\,.
\]
Here, $B_1$ and $B_2$, each ask~$q$ oracle queries and have time complexity~$O(t+qm)$.
\end{theorem}
The proof appears in Appendix~\ref{app:xxx}.  We note that Kirsch and Mitzenmacher~\cite{xxx} show
that the ($r=1$, zero-query) FP-probability for~$\Pi_\mathrm{lin}$ is
always within $O(1/n)$ of $(1-e^{-kn/m})^k$, although the asymptotic
rate of convergence is faster than~$1/n$.  The factor of $\dbinom{q}{r}$ arises as a result
of moving from the adaptive to the zero-query setting.  Finally, $\dbinom{q}{r} \leq q^r$ (with
reasonable tightness when~$r$ is small) in which case the final term in the bound behaves as
$(q (1-e^{-kn/m})^k + O(q/n) )^r$; loosely, the bound one expects for
trying to find a single FP in each of~$r$ independent``rounds'', each round
consisting of~$q$ attempts.

\todo{Privacy theorem for the ``plain'' linear-PRF scheme. Does not
  follow from Jon's general theorem.}

%%%%%%%%%%%%%%%%% BIGRAM LINEAR-PRF (AKA "NEIDERMAYER")  %%%%%%%%%%%%%%%%%%%%
\heading{Bigram Linear-PRF construction (``Neidermayer''). }
\todo{Correctness theorem for this scheme.  Should follow pretty closely the one for ``plain'' linear-PRF.}

%Next we consider the privacy of this construction, relative to a leakage function that behaves as follows.  On input a set $S=\{x_1,x_2,\ldots,x_n\}$, it computes $B_i \gets \mathsf{bigram}(x_i)$ for each $i \in [n]$.  Then, for all $1 \leq c \leq p$, and all size-$c$ subsets $\{j_1,j_2,\ldots,j_c\} \subseteq p$, it computes $L{j_1,j_2,\ldots,j_c}=|B_{j_1} \cap B_{j_2} \cap \ldots \cap B_{j_c}|$.  That is, it computes all of the $c$-way intersections. It returns $|S|=n$ and all of the $2^p -1$ intersection sizes as the leakage. \todo{Explain why this is plausibly leaked by $\pubaux$ for this construction.} \tsnote{This is exponential in size, so that means a simulator that reads the entire leakage will also be exponential-time in~$p$.  } \tsnote{Should we be considering smaller, but less realistic leakage, like $\mathsf{leak}(S)=S\setminus\{x\}$.}

Next we exhibit an efficient SS-privacy attack even when simulator is provided nearly the entire set.  Consider the following leakage function.  On input a set~$S=\{x_1,x_2,\ldots,x_n\}$, it assigns $x'_n \gets x_n[1:|x_n|-1]$ and returns $\mathsf{leak}(S)=\{x_1,x_2,\ldots,x'_n\}$.  

\begin{figure}
\centering
\fpage{.5}
{
\adversaryv{A}\\
On input $\emptystring$:\\
\nudge $x_1 \gets \mathrm{cab}$\\
\nudge $x_2 \gets \mathrm{bab}$\\
\nudge $z \getsr \bits$\\
\nudge if $z=1$ then $x_3 \gets \mathrm{caba}$\\
\nudge else $x_3 \gets \mathrm{cabc}$\\
\nudge Return $S=\{x_1,x_2,x_3\}$\\
On input $\pub \neq \emptystring$:\\
\nudge $M_1,M_2,M_3 \gets \pub$\\
\nudge $M_{1,2} \gets M_1 \vee M_2$\\
\nudge if $z=1 \wedge \left(\mathsf{hamming}(M_{1,2} \wedge M_3) = 4k\right)$ then \\
\nudge\nudge Return 1 \\
\nudge if $z=0 \wedge \left(\mathsf{hamming}(M_{1,2} \wedge M_3) = 3k\right)$ then \\
\nudge\nudge Return 1 \\
\nudge Return 0
}
\caption{Adversary for Theorem~\ref{thm:bi-lin-ss}}
\label{fig:adv-bi-lin-ss}
\end{figure}

\begin{theorem}\label{thm:bi-lin-ss}
Let $\Pi_{\mathrm{bi-lin}}= (\calQ,\Rep, \Qry)$ be the set-multiplicity data structure described in Figure~\ref{fig: neidermayer}, but instantiated with $F_{K_1},F_{K_2}$ replaced by independent random functions~$\rho_1,\rho_2$ (respectively).  Let $\leak$ be the leakage function just described.   Let~$\univ=\{\mathrm{a,b,c}\}^*$. Let $n=3$,  $m=3\alpha $ for integer $\alpha >> 1$, and let, $k = \lceil \ln(2) \alpha \rceil$.\tsnote{This value of~$k$ is from the classical analysis for minimizing the FP rate for a Bloom filter, and is set this way for compatibility with classical results.  It isn't used in any essential way in the proof sketch.}  Let~$A$ be the adversary in Figure~\ref{fig:adv-bi-lin-ss}.  Then for any simulator $\Sim$,
the advantage $\AdvPrivSS{\Pi_{\mathrm{bi-lin}},\leak}{A,\Sim}$ can be made arbitrarily close to $1/2$ by choice of~$\alpha$.

\end{theorem}
\begin{proof}(Sketch.)
On input the set~$S$ produced by~$A$, the $\Rep$ algorithm turns $x_1=$'cab', $x_2=$'bab' and $x_3$ into their respective bigram sets: $B_{x_1}=\{\sqcup\mathrm{c},\mathrm{ca},\mathrm{ab},\mathrm{b}\sqcup\}$, $B_{x_2}=\{\sqcup\mathrm{b},\mathrm{ba},\mathrm{ab}, \mathrm{b}\sqcup \}$; the set $B_{x_3}$ will be either $\{\sqcup\mathrm{c},\mathrm{ca},\mathrm{ab},\mathrm{ba}, \mathrm{a}\sqcup\}$, or $\{\sqcup\mathrm{c},\mathrm{ca},\mathrm{ab},\mathrm{bc}, \mathrm{c}\sqcup\}$, each with probability 1/2.  It then produces $\alpha$-bit arrays $M_1, M_2, M_3$ by hashing the corresponding bigram sets using the hash functions $h_j(s)=\rho_1(s)+ j\rho_2(s) \bmod m$.  Note that for sufficiently large~$m$, each of $M_1,M_2$ will contain exactly $4k$ positions set to 1; this is with overwhelming probability (up to collisions in the hash functions for different bigrams within a given bigram set).   Likewise, $M_{1,2}=M_1 \vee M_2$ will have exactly $6k$ positions set to 1, because $B_{x_1}$ and $B_{x_2}$ share $\mathrm{ab}$ and $\mathrm{a}\sqcup$.

In the case that $B_{x_3}=\{\sqcup\mathrm{c},\mathrm{ca},\mathrm{ab},\mathrm{ba}, \mathrm{a}\sqcup\}$, only one of its elements ($\mathrm{a}\sqcup$) is not in either of $B_{x_1},B_{x_2}$.  Hence, the hamming weight of $M_{1,2}\wedge M_3$ will be $4k$.  On the other hand, when $B_{x_3} = \{\sqcup\mathrm{c},\mathrm{ca},\mathrm{ab},\mathrm{bc}, \mathrm{c}\sqcup\}$, two of its elements ($\mathrm{bc}, \mathrm{c}\sqcup$) are not covered by $B_{x_1},B_{x_2}$.  In this case, the hamming weight of $M_{1,2} \wedge M_3$ will be $3k$.  Thus $\ExpPrivSSreal{\Pi_{\mathrm{bi-lin}}}{A}=1$ with overwhelming probability.  

On the other hand, the simulator~$\Sim$ is given 'cab','bab','cab' as input.  It can perfectly simulate $M_1,M_2$ by lazily sampling random functions~$\rho_1,\rho_2$ itself.  However, it has no information about the bit~$z$, so at best it can cause~$A$ to output 1 with probabilility~$1/2$.
\end{proof}

%%%%%%%%%%%%%%%%% DOMAIN-SEPARATED PRF %%%%%%%%%%%%%%%%%%%%

\heading{Construction of PRF with domain separation.}
Let $\Pi_{\mathrm{ds}}= (\calQ,\Rep, \Qry)$ be a set-multiplicity data structure defined on the right-side of Figure~\ref{fig:lin-and-ds}.  As with the preceding theorem, the following says (informally) that if~$F$ is a secure PRF, then this domain-separated PRF construction is correct against adaptive adversaries.  We note that Neidermayer et al. in~\cite{xxx} suggest replacing the linear-PRF hash functions in the previous construction with independently keyed PRFs as a way to thwart their attacks.  The construction we consider now achieves the same end, albeit via explict domain separation rather than separate keys.


\begin{theorem}\label{thm2}\label{thm:ds-correctness}
Fix $k,m,n,r>0$, and let $\Pi_{\mathrm{ds}}= (\calQ,\Rep, \Qry)$ be the set-multiplicity data structure in Figure~\ref{fig:lin-and-ds}. Let $\distr{}{}$ be a distribution over~$\mathcal{S}$.  For any adversary~$A$ that makes a total of~$q$ queries to its oracle and has time-complexity~$O(t)$, there exists a prf-adversary ~$B$ (explicitly constructed in the proof of this theorem) such that
\[
\AdvCorrect{\Pi_{\mathrm{ds}},\distr{}{},r}{A} \leq  \AdvPRF{F}{B}  + {\dbinom{q}{r}} \left( (1-e^{-kn/m})^k + O(1/n) \right)^r\,.
\]
Here, $B$ asks $q$ queries, and has time complexity $O(t+qm)$.
\end{theorem}

\begin{theorem}\label{thm:ds-ss}
Fix $k,m,n>0$, and let $\Pi_{\mathrm{ds}}= (\calQ,\Rep, \Qry)$ be the set-multiplicity data structure described in Figure~\ref{fig:lin-and-ds}.  For any set~$S$, let $\leak(S)=|S|$.  There exists a simulator~$\Sim$ such that, for any adversary~$A$
\[
\AdvPrivSS{\Pi_{\mathrm{ds}},\leak}{A,\Sim} \leq  \AdvPRF{F}{B}
\]
where~$B$ is constructed from~$A$.  (Both~$B$ and~$\Sim$ are explicitly constructed in the proof of this theorem.)
\end{theorem}
\begin{proof}[Proof (sketch). ] \todo{Move this sketch to be a proof
    of Jon's meta-result. Downgrade theorem to be a corollary of that
    result, the proof simply being a description of how $\Rep$
    decomposes into $\Rep_1$ and $\Rep_2$.}
Adversary~$B^{f}$ simulates the steps of $\ExpPrivSSreal{\Pi_{\mathrm{ds}}}{A}$, using its oracle to simuate~$\Rep(S)$.  When~$f=F_K$ then the simulation is perfect.  When~$f=\rho$ then~$B$ simulates $\ExpPrivSSreal{\overline{\Pi}_{\mathrm{ds}}}{A}$ where $\overline{\Rep}$ effectively uses~$k$ independent random functions as the hash functions.  But the $\pub$ produced by $\overline{\Rep}$ has a distribution that depends only~$|S|=n$, not the specific elements of~$S$, and the other public parameters~$m,k$.  Thus, a simulator~$\Sim$ given only $\leak(S)=|S|$ can produce a correct~$\pub$ as follows: starting with an all-zeros array~$M$ of length~$m$, uniformly sample (with replacement)~$nk$ integers in~$[m]$ and set the resulting positions of~$M$ to 1.
\end{proof}


%%%%%%%%%%%%%%%%% CLASSICAL BLOOM FILTER IN ROM %%%%%%%%%%%%%%%%%%%%

\heading{Classical Bloom filter in random oracle model (ROM). }
Fix $n,k,m \geq 0$ and let $\mathcal{S}=[\univ]^n$.  Then $\Pi_{\mathrm{Bloom}}= (\calQ,\Rep, \Qry)$ is defined as in Figure~\ref{fig:bf-and-garbled-bf} (left side).  The following result shows,

\begin{theorem}\label{thm3}\label{thm:bf-correctness}
Fix $k,m,n,r>0$, and let $\Pi_{\mathrm{Bloom}}= (\calQ,\Rep, \Qry)$ be the set-multiplicity data structure just described. For any adversary~$A$ that makes a total of~$q_T$ queries to the $\Test$ oracle, and $q_R$ queries to the RO, and has time-complexity~$O(t)$,
\[
\AdvCorrect{\Pi_{\mathrm{Bloom}},\distr{\calS}{},r}{A} \leq  {\dbinom{q_T + q_H}{r}} \left( (1-e^{-kn/m})^k + O(1/n) \right)^r\,.
\]
\end{theorem}

\input{Theorem3_FP}

\todo{Below are two lists of things that we should show.}

\heading{Correctness. }  Here we give security proofs and attacks with respect to the correctness notions.
\begin{itemize}
\item Show Bloom Filter is correct in the ROM. \jnote{Should follow along the lines
of Theorem~2, but taking into account adversary's oracle queries.}
\item correctness security/attacks on the bigram/PRF-based double-hashing construction ($h_j(x) = F_{K1}(x) + j\cdot F_{K2}(x) \bmod m$ where the~$x$ are bigrams of names, etc.)
\jnote{Done}
\item correctness-security/attacks on the bigram/domain-separated PRF construction ($h_j(x)=F_K(\langle j,x \rangle) \bmod m$, or just assume range of~$F$ is $[m]$.) \jnote{Done}
\item correctness-security/attacks Dong, Chen, Wen ``garbled Bloom filter'' construction

\end{itemize}

\heading{Privacy. } Here we give security proofs and attacks with respect to the privacy notions we have defined.
\tsnote{Under our current notions, you can never hope to prove privacy bounds that beat the element wise min-entropy of $\distr{}{}$.}
\begin{itemize}
\item Prove that the basic BF, in the ROM, is private.  \tsnote{Relative the strongest notion for which this is true.  If it isn't true for all, then give the attack(s).}

\item As a simple corrolary, show that the basic BF with $h_j(x)=F_K(\langle j,x \rangle)$ is private.  \tsnote{I believe this also shows that the bigram/PRF approach examined by Neidermayer et al.\ is secure when the hash functions are the $h_j(x)$ just described.  This was, in fact, one of the countermeasures they proposed. }

\item Prove privacy bounds for the constructions from NY. \jnote{Is this interesting?}

\item Cast Neidermayer et al.\ attacks on the bigram/PRF-based double-hashing construction (see their paper) into our formalism.  \tsnote{Note that their attack would allow one to recover \emph{every} name, not just one.}

\item Prove a privacy bound for the bigram/PRF-based double-hashing construction that Neidermayer et al.\ attacks. I expect that the provable security bound is considerably worse than the min-entropy because of the way the representation is made.  (Essentially, the Hamming weight of the representation is a good estimate of the length of the longest surname in filter.)
\jnote{Maybe tailor leakage function appropriately, i.e., so that
it only leaks the number of bigrams?}

\item Attack priv-security of Dong, Chen, Wen ``garbled Bloom Filter'' construction when the hash functions are public.\tsnote{I give the attack in the related work section.  Copy it here and flesh it out.}  Prove priv-security privacy of construction when hash functions are secret.  \tsnote{Makes the point that the application setting really matters.}

\item Prove privacy bounds of other suggestions, such as the record-level BF from Durham et al.?  This would be a nice pairing with the Neidermayer et al.\ results

\item ...
\end{itemize}
