\section{Achieving Security Notions}

\jnote{Organize by scheme, not by security notions.
}
\include{scheme-descriptions}

\heading{Linear-PRF construction. }
Here we consider a set-multiplicity data structure that was attacked by Neidermayer et al. in~\cite{xxx}. Fix $n,k,m \geq 0$ and let $\mathcal{S}=[\univ]^n$.  Then $\Pi_{\mathrm{lin}}= (\calQ,\Rep, \Qry)$ is defined as in Figure~\ref{fig:lin-and-ds} (left side).  The following result shows, informally, that if~$F$ is a good PRF, then $\Pi_\mathrm{lin}$ is correct against adaptive error-finding adversaries. 

\begin{theorem}\label{thm1}
Fix $k,m,n,r>0$, and let $\Pi_{\mathrm{lin}}= (\calQ,\Rep, \Qry)$ be the set-multiplicity data structure described in Figure~\ref{fig:lin-and-ds}. Let $\distr{}{}$ be a distribution over~$\mathcal{S}$.  For any adversary~$A$ that makes a total of~$q$ queries to its oracle and has time-complexity~$O(t)$, there exist prf-adversaries~$B_1,B_2$ (explicitly constructed in the proof of this theorem) such that
\[
\AdvCorrect{\Pi_{\mathrm{lin}},\distr{}{},r}{A} \leq  \AdvPRF{F}{B_1} + \AdvPRF{F}{B_2}  +{\dbinom{q}{r}} \left( (1-e^{-kn/m})^k + O(1/n) \right)^r\,.
\]
Here, $B_1$ and $B_2$, each ask~$q$ oracle queries and have time complexity~$O(t+qm)$.
\end{theorem}
Before giving the proof, we note that Kirsch and Mitzenmacher~\cite{xxx} show
that the ($r=1$, zero-query) FP-probability for~$\Pi_\mathrm{lin}$ is
always within $O(1/n)$ of $(1-e^{-kn/m})^k$, although the asymptotic
rate of convergence is faster than~$1/n$.  The factor of $\dbinom{q}{r}$ arises as a result
of moving from the adaptive to the zero-query setting.  Finally, $\dbinom{q}{r} \leq q^r$ (with
reasonable tightness when~$r$ is small) in which case the final term in the bound behaves as
$(q (1-e^{-kn/m})^k + O(q/n) )^r$; loosely, the bound one expects for
trying to find a single FP in each of~$r$ independent``rounds'', each round
consisting of~$q$ attempts.

\heading{Construction of PRF with domain separation.}
Let $\Pi_{\mathrm{ds}}= (\calQ,\Rep, \Qry)$ be a set-multiplicity data structure defined on the right-side of Figure~\ref{fig:lin-and-ds}.  As with the preceding theorem, the following says (informally) that if~$F$ is a secure PRF, then this domain-separated PRF construction is correct against adaptive adversaries.


\begin{theorem}\label{thm2}
Fix $k,m,n,r>0$, and let $\Pi_{\mathrm{ds}}= (\calQ,\Rep, \Qry)$ be the set-multiplicity data structure in Figure~\ref{fig:lin-and-ds}. Let $\distr{}{}$ be a distribution over~$\mathcal{S}$.  For any adversary~$A$ that makes a total of~$q$ queries to its oracle and has time-complexity~$O(t)$, there exists a prf-adversary ~$B$ (explicitly constructed in the proof of this theorem) such that
\[
\AdvCorrect{\Pi_{\mathrm{ds}},\distr{}{},r}{A} \leq  \AdvPRF{F}{B}  + {\dbinom{q}{r}} \left( (1-e^{-kn/m})^k + O(1/n) \right)^r\,.
\]
Here, $B$ asks $q$ queries, and has time complexity $O(t+qm)$.
\end{theorem}

%%%%%%%%%%
\input{ds-ss-proof}
%%%%%%%%%%


\todo{Below are two lists of things that we should show.}

\heading{Correctness. }  Here we give security proofs and attacks with respect to the correctness notions.
\begin{itemize}
\item Show Bloom Filter is correct in the ROM. \jnote{Should follow along the lines
of Theorem~2, but taking into account adversary's oracle queries.}
\item correctness security/attacks on the bigram/PRF-based double-hashing construction ($h_j(x) = F_{K1}(x) + j\cdot F_{K2}(x) \bmod m$ where the~$x$ are bigrams of names, etc.)
\jnote{Done}
\item correctness-security/attacks on the bigram/domain-separated PRF construction ($h_j(x)=F_K(\langle j,x \rangle) \bmod m$, or just assume range of~$F$ is $[m]$.) \jnote{Done}
\item correctness-security/attacks Dong, Chen, Wen ``garbled Bloom filter'' construction

\end{itemize}

\heading{Privacy. } Here we give security proofs and attacks with respect to the privacy notions we have defined.
\tsnote{Under our current notions, you can never hope to prove privacy bounds that beat the element wise min-entropy of $\distr{}{}$.}
\begin{itemize}
\item Prove that the basic BF, in the ROM, is private.  \tsnote{Relative the strongest notion for which this is true.  If it isn't true for all, then give the attack(s).}

\item As a simple corrolary, show that the basic BF with $h_j(x)=F_K(\langle j,x \rangle)$ is private.  \tsnote{I believe this also shows that the bigram/PRF approach examined by Neidermayer et al.\ is secure when the hash functions are the $h_j(x)$ just described.  This was, in fact, one of the countermeasures they proposed. }

\item Prove privacy bounds for the constructions from NY. \jnote{Is this interesting?}

\item Cast Neidermayer et al.\ attacks on the bigram/PRF-based double-hashing construction (see their paper) into our formalism.  \tsnote{Note that their attack would allow one to recover \emph{every} name, not just one.}

\item Prove a privacy bound for the bigram/PRF-based double-hashing construction that Neidermayer et al.\ attacks. I expect that the provable security bound is considerably worse than the min-entropy because of the way the representation is made.  (Essentially, the Hamming weight of the representation is a good estimate of the length of the longest surname in filter.)
\jnote{Maybe tailor leakage function appropriately, i.e., so that
it only leaks the number of bigrams?}

\item Attack priv-security of Dong, Chen, Wen ``garbled Bloom Filter'' construction when the hash functions are public.\tsnote{I give the attack in the related work section.  Copy it here and flesh it out.}  Prove priv-security privacy of construction when hash functions are secret.  \tsnote{Makes the point that the application setting really matters.}

\item Prove privacy bounds of other suggestions, such as the record-level BF from Durham et al.?  This would be a nice pairing with the Neidermayer et al.\ results

\item ...
\end{itemize}
