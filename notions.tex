\section{Security Notions}
\label{sec:security-notions}
\tsnote{intro text}
Following NY, we are interested in defining an adaptive (i.e.,
adversarial) notion of correctness.   
In addition to correctness, we establish three notions of privacy for
set-representations. The first two have the flavor of a one-wayness game, in which the adversary is given the auxiliary information~$\aux$ and, either the representation~$M$ or the abillity to call an oracle that evaluates $\Qry(M,\aux,q)$ on queries~$q$ of its choosing.  At the end of this game, the adversary must output some point in the set represented by~$M$.  In the second privacy notion, the adversary presents two sets~$S_0$ and $S_1$ (of equal size) and a representation~$M$ is created for one of these two. Then the adversary is given $\aux$ and oracle access to $\Qry(M,\aux,q)$, and it must decide which set~$M$ represents.

\subsection{Correctness Against Adaptive Adversaries}

First, a set~$S$ is chosen according to some
distribution~$\distr{\calS}{}$ over the collection of multisets
$\mathcal{S}$ associated to~$\Pi$, and then
$\Rep(S)$ is run to generate $(M,\aux)$.
%(Unless stated otherwise, we assume security holds for all distributions and thus for all sets $S$.)
Adversary~$A$ is given~$\calS$ and $\aux$~as input; it is
provided an oracle~$\TestOracle$ that, on input a query~$q \in \calQ$,
computes (and returns) the result of $\Qry(M,\aux,q)$, and increments
a counter if this result is in error.  The adversary wins if it
manages to cause at least~$r>0$ such errors among its queries.

The notion is lifted to the random-oracle model by providing
$\Rep,\Qry$ and the adversary~$A$ with oracle access to the
random-oracle(s).



\begin{figure}[htp]
\centering
\fpage{.6}{
\hpagess{.6}{.35}
{
\experimentv{$\ExpCorrect{\setprim,\distr{\calS}{},r}{A}$}\\
$S \getsr \distr{\calS}{}$\\
$\mathrm{err}\gets 0$\\
$(M,\aux) \getsr \Rep(S)$\\
$z \getsr A^{\TestOracle}(S,\aux)$\\
if $\mathrm{err} < r$ then Return 0\\
Return 1
}
%
{
\oracle{$\TestOracle(q)$}\\
$a \gets \Qry(M,\aux,q)$\\
if $a \neq q(S)$ then \\
\nudge $\mathrm{err}\gets\mathrm{err}+1$\\
Return~$(a,\mathrm{err})$
}
}
\caption{Correctness of~$\Pi$ against (adaptive) adversary~$A$, when
  the target multiset~$S$ is sampled from~$\calS$ according to distribution~$\distr{\calS}{}$.} 
\label{fig:correctness}
\end{figure}

In this experiment we track the time-complexity (relative to some
implied model of computation) and query-complexity (i.e., number of
queries) of the adversary~$A$.  
We define the advantage of adversary~$A$ in the correctness experiment as 
$\AdvCorrect{\Pi,\distr{\calS}{},r}{A} = \Prob{\ExpCorrect{\Pi,\distr{\calS}{}, r,}{A}=1}$.
Overloading notation, we write $\AdvCorrect{\Pi,\distr{\calS}{},r}{t,q}$ for the maximum over all~$t$-time adversaries that ask at most~$q$ queries. Roughly, we say that a
set-representation~$\Pi$ is $(t,q,r,\epsilon')$-correct if $\AdvCorrect{\Pi,\distr{\calS}{},r}{t,q} \leq \epsilon'$.  




%
%And if the experiment requires the adversary to induce~$r$ errors, the attack wins iff
%$N \stackrel{{\rm def}}{=} \sum_{i=1}^T X_i \geq r$.  Modelling the $X_i$ as independent Bernoulli trials with
%probability~$\epsilon$ gives $N$ a binomial distribution.  \fixme{Something feels wrong with this...}  
%Writing $\bin(T, \epsilon; r)$ for the probability that $N \geq r$,
%we conclude that the \emph{best} correctness we can hope for against adversaries making~$T$ queries is  $\bin(T,\epsilon; t))$. %\jnote{Need to find different terms to use for a query $q \in \mathcal{Q}$
%and a query that the attacker makes to its oracle.}
%\tsnote{Viewed another way, we could let~$T$ be a negative binomial RV, and ask how many queries are needed (w.h.p) for $N \geq t$.} 
%
%\jnote{One option is to define the adversary's \emph{advantage} as the difference between
%its success probability and the success probability of the above,
%trivial attack. Just a thought.}
%\tsnote{Or, perhaps by recasting security
%  as distinguishing between $\Qry(M,\aux,\cdot)$ and an oracle that
%  returns 0,1 according to Bernoulli with paramter~$\epsilon$.}
%\fixme{Not clear this attack is generically applicable enough to serve as a reference/baseline.  (See email discusssion 7/23.)  Might be worth pointing out that this intuition, between non-adaptive error-probability and the expected number of queries to find an error, can be quite misleading.}

\heading{Comparison to Naor-Yogev definition.}
The style of the Naor-Yogev (NY) definition is slightly different. \jnote{Even if we ignore
all the other issues, chief among them the inconsistent way it treats the hash functions.}
Lifting their definition to our setting, the experiment is similar but the attacker
succeeds only if it outputs a single query $q$ for which $\Qry( M,
\aux, q) \neq q(S)$  \emph{subject to the restriction that it did not query $q$ to its $\Qry$ oracle}.
It will be interesting to understand formally the relation between our definition and theirs.
Here are some observations:
\begin{enumerate}
\item Say a scheme is $\epsilon_{NY}$-secure under the NY definition.
Then we claim it is $(t,q, r, q\epsilon_{NY}/r)$-correct. To see
this, assume not. Then there is a $t$-time attacker~$A$ that, with
probability at least $\epsilon'=q\epsilon_{NY}/r$,
issues~$q$ Test-queries of which at least~$r$ cause errors. If we simply run~$A$ and then choose a random Test-query to
output, we succeed with probability at least $\epsilon' \cdot r/q$. It is unclear whether this is tight.

\item There is a contrived scheme that is $(t, q, 2, 0)$-correct but not NY-secure at all; the basic idea is
to have a set-representation that always has \emph{exactly one} false positive that is easy to find
given the public information.

\item If a scheme is $(t,q,1,\epsilon)$-correct, then it is also $\epsilon$-secure under the NY definition,
at least for attackers making at most $q-1$ queries.
This is immediate.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Notions of Privacy}
One can also consider the orthogonal notion of privacy for a set-representation.
\jnote{Actually, I am now unsure what the right way to define it is. It seems natural
to give the attacker $\aux$. But if we give them $\aux$ and $M$ then they have everything.
If $S$ has high min-entropy (element-wise), then it might still be
possible to have security here.}\tsnote{I think we will always bump up
against the (element-wise) min-entropy of the distribution over~$S$,
at least in the ``one-wayness'' style definition that I had been imagining. }
There are several possible definitions:
\begin{enumerate}
\item A ``one-wayness'' definition where $S$ has high min-entropy (element-wise), and we
give the attacker $\aux$ and either $M$ or oracle access to $\Qry$. The attacker
succeeds if it can output an element in~$S$. \tsnote{Neither of these seems to capture the Neidermeier et al. attack.  Giving the adversary~$M$ is closest, but our syntax would put the hash function secret keys into~$M$, which the Neidermeier attack doesn't get.}

\item An ``indistinguishability'' definition where either $S_0$ or $S_1$ is used, and the attacker
must determine which. Here the attacker is given $\aux$ but only oracle access to $\Qry$, and
it is disallowed from asking any query $q$ for which $q(S_0) \neq
q(S_1)$. \tsnote{I'm not convinced this is the right restriction.
  This says that security is required \emph{only} for properties that are
  true of both sets.  So a scheme with $M=S$ will be trivially secure
  against set membership queries.  Maybe we restrict from queries~$q$ that are a priori known to have the same value for all sets~$S \in \calS$, or all~$S$ of a given size, etc., as these might be pointless?)}

\tsnote{Is this the right kind of indistinguishability anyway?  This current notion says, in effect, that $S_0$ and $S_1$ are indistinguishable \emph{with respect to the allowed queries} (assuming that $\aux$ doesn't stupidly leak information.)  But why not try to formalize the intution that a representation~$M$ and the public info~$\aux$ tell you nothing (non-trivial) about the set being represented, period?  (Classical BFs, by the way, essentially leak the number of elements in the set by looking at the number of 0-bits in the array.)   That's tricky to define... Also, if you give~$M$ to the adversary, how do you handle the fact that, under our current syntax, $M$~may contain secret keys, etc.?}
%\tsnote{How will the adversary know that a query satisfies
%  this in (say) the case of the classical BF?  We can, of course,
%enforce it in the experiment, but then our resource accounting risks
%overcounting the number of queries.} \jnote{I was assuming the attacker knows $S_0, S_1$.}
%\tsnote{Also, we need that, in general, $\aux$ itself
%does not leak information about~$S_0$ vs.\ $S_1$. } \jnote{Sure, this would be implied
%by the definition in this case.}
\end{enumerate}

\begin{figure}[htbp]
\centering
\hfpages{.495}{
\hpagess{.5}{.45}
{
\experimentv{$\ExpWPriv{\setprim,\distr{\calS}{}}{A}$}\\
$S \getsr \distr{\calS}{}$\\
$(M,\aux) \getsr \Rep(S)$\\
$z \getsr A^{\TestOracle}(\aux)$\\
if $z \in S$ then Return 1\\
Return 0\\

\medskip
\experimentv{$\ExpPriv{\setprim,\distr{\calS}{}}{A}$}\\
$S \getsr \distr{\calS}{}$\\
$(M,\aux) \getsr \Rep(S)$\\
$z \getsr A(M,\aux)$\\
if $z \in S$ then Return 1\\
Return 0\\
}
%
{
\oracle{$\TestOracle(q)$}\\
$a \gets \Qry(M,\aux,q)$\\
Return~$a$
}
}
%
{
\hpagess{.485}{.5}
{
\experimentv{$\ExpPrivInd{\setprim,\distr{\calS}{}}{A}$}\\
$b \getsr \bits$\\
$S_0,S_1 \getsr \distr{\calS}{}$\\
$(M,\aux) \getsr \Rep(S_b)$\\
$b' \getsr A^{\TestOracle}(S_0,S_1,\aux)$\\
if $b' = b$ then Return 1\\
Return 0\\
}
%
{
\oracle{$\TestOracle(q)$}\\
$a \gets \Qry(M,\aux,q)$\\
Return~$a$\\

\medskip
\oracle{$\RepOracle(S_0,S_1)$}\\
if $\mathrm{used}=\true$ then Return $\bot$\\
%if $|S_0|\neq|S_1|$ then \\
%\nudge Ret $\bot$\\
$S_0,S_1 \getsr \distr{\calS}{}$\\
$\mathrm{used}=\true$\\
$(M,\aux) \getsr \Rep(S_b)$\\
Return $(S_0,S_1,\aux)$\\

}
}
\caption{Privacy notions. {\bf Left:} ``One-wayness'' style
  definitions. The top is a weaker notion, because the representation
  is hidden from the adversary. {\bf Right:} An
  ``indistinguishability'' style notion. (Still playing... ignore unused oracles)} 
\label{fig:privacy}
\end{figure}

\subsection{Relationships Among Notions}
If we allow for trivial schemes, e.g. $M=S$, then correctness and the stronger version of one-wayness privacy (Priv) are clearly orthogonal.\tsnote{In general, it isn't clear how to reduce correctness to the Priv notion.  In the correctness experiment, you get~$(S,\aux)$ but not~$M$; whereas in the Priv-notion, the adversary expects~$(M,\aux)$ as input.  Unless the coins of Rep are effectively leaked in~$\aux$, you can't reliably produce~$M$ given~$(S,\aux)$.}
Curiously, $M=S$ does seem to be both correct and private (up to the element-wise min-entropy of~$S$) in the weaker version of one-wayness privacy (wPriv).
\tsnote{Reducing correctness to the weaker version, wPriv, is syntactically possible, but not clear how to connect the success events.  In the one-wayness game, you win by outputing an element of~$S$; but how does this lead to finding an error-inducing query?  Maybe the one-wayness attacker makes no queries, and just outputs a point~$z$.  Then the correctness attacker does what?  Ask some query~$q_z$ related to~$z$ ---remember, queries are not syntactically restricted to set membership!--- and see if the oracle returns the true value $q_z(S)$?  This is pretty complicated... and it's not clear how to do a quality reduction.   }


\tsnote{Likewise the other way: the one-wayness adversary does not get~$S$, and yet needs to provide this to the correctness adversary.}
