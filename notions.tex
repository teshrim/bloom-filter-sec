\section{Security Notions}
\label{sec:security-notions}
Following NY, we are interested in defining an adaptive (i.e.,
adversarial) notion of correctness.
In addition to correctness, we establish notions of privacy for
set-multiplicity data structures.

\tsnote{flesh out}

\subsection{Correctness Against Adaptive Adversaries}

First, a set~$S$ is chosen according to some
distribution~$\distr{}{}$ over the collection of multisets
$\mathcal{S}$ associated with~$\Pi$, and then
$\Rep(S)$ is run to generate $(\pubaux,\privaux)$. \jnote{I thought we were going to let
the adversary choose~$S$?} \jnote{If instead we choose $S$ from ${\cal D}$, then
is it clear we want to give $S$ to~$A$?}
%(Unless stated otherwise, we assume security holds for all distributions and thus for all sets $S$.)
Adversary~$A$ is given~$\pubaux$~as input; it is also
provided with access to an oracle~$\TestOracle$ that, on input a query~$q \in \calQ$,
returns $\Qry(\pubaux,\privaux,q)$ and increments
a counter if this result is in error.  The adversary wins if it
manages to cause at least~$r>0$ such errors among its queries.
\jnote{If we are specializing the set-multiplicity data structures then we
may as well have the attacker query $x$ which gets translated to query $q_x$. If
we are trying to be more general then we should be consistent.} \jnote{Why does $A$ output
anything at all?}

The notion is lifted to the random-oracle model by providing
$\Rep,\Qry$ and the adversary~$A$ with oracle access to the
random-oracle(s).

\jnote{I changed $\TestOracle$ so that it outputs $(a, q(S))$ rather
than $(a,\mathrm{err})$. Note that the latter can be computed from the former,
and in the general case I think the former is what we want.} \jnote{I also changed
the definition so the adversary has to find $r$ {\bf unique} inputs on which
there is an error.}


\begin{figure}[htp]
\centering
\fpage{.65}{
\hpagess{.5}{.45}
{
\experimentv{$\ExpCorrect{\setprim,\distr{}{},r}{A}$}\\
$S \getsr \distr{}{}$\\
$\mathcal{Q} \gets \emptyset$ \\
$\mathrm{err}\gets 0$\\
$(\pubaux,\privaux) \getsr \Rep(S)$\\
$z \getsr A^{\TestOracle}(S,\pubaux)$\\
if $\mathrm{err} < r$ then Return 0\\
Return 1
}
%
{
\oracle{$\TestOracle(q)$}\\
$a \gets \Qry(\pubaux,\privaux,q)$\\
if ($a \neq q(S)$ and $q \not \in \mathcal{Q}$) then \\
\nudge $\mathrm{err}\gets\mathrm{err}+1$\\
$\mathcal{Q} \gets \mathcal{Q} \cup \{q\}$ \\
Return~$(a,q(S))$
}
}
\caption{Correctness of~$\Pi$ against an (adaptive) adversary~$A$, when
  the represented multiset~$S$ is sampled according to distribution~$\distr{}{}$.}
\label{fig:correctness}
\end{figure}

In this experiment we track the time complexity (relative to some
model of computation) and query complexity (i.e., number of
queries to $\TestOracle$) of~$A$.
We define the advantage of adversary~$A$ in the correctness experiment as
$\AdvCorrect{\Pi,\distr{}{},r}{A} = \Prob{\ExpCorrect{\Pi,\distr{}{}, r}{A}=1}$.
Overloading notation, we write $\AdvCorrect{\Pi,\distr{}{},r}{t,q}$ for the maximum over
all~$t$-time adversaries that ask at most~$q$ queries. We say that a
set-representation data structure~$\Pi$ is $(t,q,r,\epsilon)$-correct if $\AdvCorrect{\Pi,\distr{}{},r}{t,q} \leq \epsilon$.
\jnote{Note~$q$ is overloaded here.}
%\jnote{Note that test includes err because we don't want to penalize
%the adversary's resources for computing $q(S)$.}

\jnote{Case of $r=1$ does not necessarily imply anything for $r>1$: can have a scheme
where finding the first false positive is hard but then the rest are easy; can have
a scheme where finding one false positive is easy finding more is hard (e.g.,
because there do not exist
any more).}

\heading{Comparison to the Naor-Yogev definition.}
The structure of the Naor-Yogev definition is different from ours.
Lifting their definition\footnote{They focus specifically on set-representation data structures
with no false negatives, and consider worst-case choice of~$S$. Their data-structure syntax
also does not distinguish public and private portions of the representation. Nevertheless, it is straightforward
to extend their definition to more closely match ours.}
to our setting,
the experiment is similar but the attacker
succeeds only if it outputs a (single) query $q$ for which
$\Qry(\pubaux,\privaux, q) \neq q(S)$  \emph{subject to the restriction that it did not
previously query $q$ to its $\TestOracle$ oracle}. We refer to
Figure~\ref{fig:NYcorrectness} for a definition of the relevant experiment.
We define the advantage of adversary~$A$ as
$\NYAdvCorrect{\Pi,\distr{}{}}{A} = \Prob{\NYExpCorrect{\Pi,\distr{}{}}{A}=1}$,
and write $\NYAdvCorrect{\Pi,\distr{}{},r}{t,q}$ for the maximum over
all~$t$-time adversaries that ask at most~$q$ queries. We say that a
set-representation data structure~$\Pi$ is $(t,q,\epsilon)$-NY-correct if
$\NYAdvCorrect{\Pi,\distr{}{}}{t,q} \leq \epsilon$. \jnote{This should all probably
move to an appendix; it's a lot of notation to digest for something we never use again
in the paper.}

\jnote{Just noticed something (else) odd about the NY definition: we cannot assume w.l.o.g.\
that $A$ makes exactly $q$ queries, and in fact it is possible to have cases where increasing
the number of queries the attacker makes can decrease its advantage! This seems like
another drawback of the definition.}

\begin{figure}[htp]
\centering
\fpage{.6}{
\hpagess{.5}{.45}
{
\experimentv{$\ExpCorrect{\setprim,\distr{}{}}{A}$}\\
$S \getsr \distr{}{}$\\
$\mathcal{Q} \gets \emptyset$\\
%$\mathrm{err}\gets 0$\\
$(\pubaux,\privaux) \getsr \Rep(S)$\\
$q \getsr A^{\TestOracle}(S,\pubaux)$\\
if $\left(q \not \in \mathcal{Q}\right.$ and \\
\nudge $\left.\Qry(\pubaux,\privaux,q) \neq q(S)\right)$ \\
\nudge \nudge then Return 1\\
Return 0
}
%
{
\oracle{$\TestOracle(q)$}\\
$a \gets \Qry(\pubaux,\privaux,q)$\\
$\mathcal{Q} \gets \mathcal{Q} \cup \{q\}$ \\
%\nudge $\mathrm{err}\gets\mathrm{err}+1$\\
Return~$(a,q(S))$
}
}
\caption{The Naor-Yogev definition of
correctness, adapted to our setting.}
\label{fig:NYcorrectness}
\end{figure}

With the above in place we can now relate their definition to ours.

\jnote{Do we have a compelling example of why the definition in Figure~\ref{fig:correctness}
is ``better'' than the definition in Figure~\ref{fig:NYcorrectness}?}

\begin{theorem}
If $\Pi$ is $(t,q,\epsilon)$-NY-correct, then it is also
$(t, q', r, q'\epsilon/r)$-correct for any $q' \leq q+1$ and $r\geq 1$.
\end{theorem}
\begin{proof}
Let $\Pi$ be a set-representation data structure that is $(t,q,\epsilon)$-NY-correct,
and assume that for some distribution $\distr{}{}$, some $q' \leq q+1$, and
some $r \geq 1$
there is an adversary $A$ running in time~$t$
and making $q'$ oracle queries such that
$\AdvCorrect{\Pi,\distr{}{},r}{A} > q'\epsilon/r$.
(Note that
we may assume $A$ always makes exactly $q'$ queries without loss of generality.)
With probability at least
$q'\epsilon/r$ in an execution of $\ExpCorrect{\Pi,\distr{}{},r}{A}$, we have that
$A$ makes at least $r$ distinct queries to $\TestOracle$ for which
an incorrect answer is returned. Let $A'$ be the algorithm that simply
runs~$A$, but chooses
uniformly one of the $q'$ queries of $A$ to its $\TestOracle$ oracle and outputs that query
as its final output. Then with probability at least $r/q' \cdot (q'\epsilon/r)=\epsilon$
the query chosen by $A'$
leads to an incorrect answer, and was not previously asked to the $\TestOracle$ oracle.
Since the running time of $A'$ is at most $t$, and it makes at most $q'-1 \leq q$ queries
to its oracle, this is a contradiction.
\end{proof}

\jnote{The above is tight, at least for $r=1$. Specifically, consider a scheme
in which every query is independently
answered incorrectly with probability~$\epsilon$. Such a
scheme will be $(t,q,\epsilon)$-NY-correct
for any $t, q$, however an adversary making $q=1/\epsilon$ queries has constant advantage
under our correctness definition (for $r=1$).}

\begin{theorem}
If $\Pi$ is $(t, q, 1, \epsilon)$-correct, then it is also $(t, q-1, \epsilon)$-NY-correct.
\end{theorem}
\begin{proof}
Let $\Pi$ be a set-representation data structure that is $(t,q,1,\epsilon)$-correct,
and assume that for some distribution $\distr{}{}$
there is an adversary $A$ running in time~$t$
and making at most $q-1$ oracle queries such that
$\NYAdvCorrect{\Pi,\distr{}{}}{A} > \epsilon$.
Let $A'$ be the algorithm that simply
runs~$A$, passing the oracle queries of $A$ to its own oracle, until $A$ terminates
with output~$q$; then, $A'$ sends $q$ to $\TestOracle$. \jnote{$q$ is (still)
overloaded!} It is immediate that $A'$ makes at most $q$ oracle queries, and
$\AdvCorrect{\Pi,\distr{}{},1}{A'} \geq \NYAdvCorrect{\Pi,\distr{}{}}{A}$, a contradiction.
\end{proof}

\begin{theorem}
There exists a set-representation data structure $\Pi$ that
is $(t, q, 2, 0)$-correct, but is not $(t, 0, \epsilon)$-NY-correct
for any $\epsilon<1$.
\end{theorem}
\begin{proof}
We prove the theorem for set-membership data structures.
Let $x \in {\cal X}$ be an arbitrary element of the universe, and
let $\Pi$ be the data structure in which $\Rep(S)$ outputs $\pubaux=\privaux=S$, and
$\Qry(S, S, q_y)$ outputs $q_y(S)$ if $y \neq x$ but outputs $1-q_x(S)$ otherwise. This
scheme always answers incorrectly for a single, fixed query, and answers
correctly for every other query. The theorem follows.
\end{proof}

\jnote{I'm not sure what to conclude from any of the results above. The proofs
are also all trivial.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\leak}{{\sf leak}}
\subsection{Privacy}
\jnote{Define appropriate notion of min-entropy for our setting.
Define one-wayness.}

In this section we specialize to the case of set-membership data structures, and
focus on sets rather than multisets.
Before continuing, it will be useful to define a notion of ``point-wise min-entropy.''
Let ${\cal D}$ be
a distribution on sets over some universe ${\cal X}$. Then the \emph{point-wise
min-entropy} of ${\cal D}$ is defined as
\[H_\infty({\cal D}) \bydef -\log \max_{x \in {\cal X}} \Pr[S \getsr {\cal D} : x \in S].\]


One can also consider the orthogonal notion of \emph{privacy} for a
data structure. \jnote{I am still hoping that we can treat data structures
at an even more general level than set-representation data structures.}
We formalize two types of privacy notions. The first captures
a ``one-wayness'' property that (informally) requires that
the representation of some set~$S$ does not make it any easier for an attacker
to learn an element of~$S$.
The second definition
captures a flavor of semantic security, essentially requiring that $M$ and $\pub$ do
not leak any information about the set~$S$ they represent beyond
what is captured in some explicit leakage function.

\jnote{OK, from here on I specialize to set-representation data structures\ldots}


Our semantic-secure definition is simulation-based (see Figure~\ref{fig:privacy-ss}).
In this definition we compare the probabilities with which an attacker $A$ outputs~1
in two experiments: one ``real'' and one ``simulated.''
In the real experiment (ss-rep-1), $A$ outputs a set $S$  and is given the
public information $\pubaux$ that results from running $\Rep(S)$.
\footnote{We do not give $A$ an oracle for issuing queries;
since $A$ knows the set~$S$, such an oracle would be superfluous.
\jnote{Interestingly,
if we provided a query oracle in the real world and an oracle that returns the correct
answer in the simulated world, then the definition seems to imply
correctness also.}}
In the simulated experiment (ss-rep-0), $A$ outputs $S$ and is given $\pubaux$ output
by a simulator $\Sim$ that is only given ${\sf leak}(S)$ for some (possibly randomized)
function~${\sf leak}$.
For a given function ${\sf leak}$, adversary $A$, and simulator~$\Sim$,
we define the advantage measure
$\AdvPrivSS{\Pi,{\sf leak}}{A,\Sim} \bydef
\left| \Prob{\ExpPrivSSreal{\Pi}{A}=1} -
\Prob{\ExpPrivSSsim{\Pi,{\sf leak}}{A, \Sim}=1} \right|$.
Informally, a scheme $\Pi$ is secure with respect to some leakage function ${\sf leak}$
if for all $A$ there is a simulator $\Sim$ such that
$\AdvPrivSS{\Pi,{\sf leak}}{A,\Sim}$ is small.
Intuitively, this means that the public portion
$\pubaux$ of the representation of a set~$S$ leaks~${\sf leak}(S)$ and nothing more.
\jnote{Need to relate running time of $\Sim$ to running time of~$A$.}
\todo{Introduce OW notion, if we keep it}
\begin{figure}[hbtp]
\centering
\fpage{.6}{
\hpagess{.5}{.45}
{
\experimentv{$\ExpPrivSSreal{\Pi}{A}$}\\
$(S,\st) \getsr A()$ \\
$(\pubaux,\privaux) \getsr \Rep(S)$\\
return $A(\st,\pubaux)$\\
}
%
{
\experimentv{$\ExpPrivSSsim{\Pi, {\sf leak}}{A, \Sim}$}\\
$(S,\st) \getsr A()$\\
$(\st,\pubaux) \getsr \Sim({\sf leak}(S))$ \\
return $A(\st,\pubaux)$\\
}
}
\caption{Experiments for a ``semantic-security'' style privacy
  definition.}
\label{fig:privacy-ss}
\end{figure}

\begin{figure}[hbtp]
\centering
\fpage{.6}{
\hpagess{.5}{.45}
{
\experimentv{$\ExpPrivOW{\setprim,\distr{}{}}{A}$}\\
$S \getsr \distr{}{}$\\
$(\pubaux,\privaux) \getsr \Rep(S)$\\
$z \getsr A^{\TestOracle}(\pubaux)$\\
if $z \in S$ then return 1\\
return 0\\
}
{
\oracle{$\TestOracle(q)$}\\
eturn $\Qry(\pubaux,\privaux,q)$
}
}
\caption{Experiments for a ``one-way'' style privacy
  definition.}
\label{fig:privacy-ow}
\end{figure}

%
%\begin{figure}[htbp]
%\centering
%\hfpages{.495}
%{
%\hpagess{.49}{.49}
%{
%
%\experimentv{$\ExpPrivSSreal{\setprim,\distr{}{}}{A}$}\\
%$S\getsr \distr{}{}$\\
%$(M,\pubaux,\privaux) \getsr \Rep(S)$\\
%$(f,v) \getsr A^{\TestOracle}(M,\pubaux)$\\
%if $f(S)=v$ then\\
%\nudge Return 1\\
%Return 0\\
%
%\medskip
%\experimentv{$\ExpPrivSSsim{\setprim,\distr{}{}}{P}$}\\
%$S\getsr \distr{}{}$\\
%$(M,\pubaux,\privaux) \getsr \Rep(S)$\\
%$(f,v) \getsr P(\pubaux)$\\
%if $f(S)=v$ then\\
%\nudge Return 1\\
%Return 0\\
%}
%%
%{
%\oracle{$\TestOracle(q)$}\\
%$a \gets \Qry(M,\pubaux,\privaux,q)$\\
%Return~$a$\\
%}
%}
%{
%\hpagess{.49}{.49}
%{
%\experimentv{$\ExpPrivSS{\setprim,\distr{}{},P}{A}$}\\
%$S\getsr \distr{}{}$\\
%$b \getsr \bits$\\
%%$(M,\pubaux,\privaux) \getsr \Rep(S)$\\
%$(M_1,\pubaux,\privaux) \getsr \Rep(S)$\\
%$M_0 \getsr P(\pubaux)$\\
%%$(f,v) \getsr \getsr A^{\TestOracle}(M,\pubaux)$\\
%$b' \getsr A^{\TestOracle}(M_b,\pubaux)$\\
%%if $f(S)=v$ then\\
%if $b'=b$ then\\
%\nudge Return 1\\
%Return 0\\
%%
%%\medskip
%%\experimentv{$\ExpPrivSSsim{\setprim,\distr{}{}}{P}$}\\
%%$S\getsr \distr{}{}$\\
%%$(M,\pubaux,\privaux) \getsr \Rep(S)$\\
%%$(f,v) \getsr P(\pubaux)$\\
%%if $f(S)=v$ then\\
%%\nudge Return 1\\
%%Return 0\\
%}
%%
%{
%\oracle{$\TestOracle(q)$}\\
%$a \gets \Qry(M_1,\pubaux,\privaux,q)$\\
%Return~$a$\\
%}
%}
%\caption{Semantic-security style privacy
%  definitions. \textcolor{red}{On the left, need to protect against
%    adversary outputting
%    things like $f(S)=M$.  One idea is to forbid~$f$ such that
%    $f(S)=f(S')$ for all $S,S'$ in the support of $\distr{}{}$.}
%    }
%\label{fig:privacy-ss}
%\end{figure}

\heading{Relationships Among Notions.} \todo{SS$\Rightarrow$OW?
  (Probably not in general, but perhaps for set-multiplicity data
  structures that satisfy certain assumptions on the query set.)
  SS$\not\Rightarrow$ correctness; the converse is already shown by
  the example I gave earlier, i.e. $M=S\setminus\{x\}$ for random $x
  \in S$.}
