
\section{Security Notions}
\label{sec:security-notions}
Following NY, we are interested in defining an adaptive (i.e.,
adversarial) notion of correctness.
In addition to correctness, we establish notions of privacy for
set-multiplicity data structures.
All adversaries are stateful by default.

\tsnote{flesh out}

\subsection{Correctness Against Adaptive Adversaries}

First, the adversary $A$ outputs a set $S$ from among those supported by
the data structure. Then,
$\Rep(S)$ is run to generate $(\pubaux,\privaux)$.
%\jnote{I thought we were going to let
%the adversary choose~$S$?} \tsnote{Email discussion. At this point,
%I'm happy just making~$S$ part of the experiment ``name'', the
%way~$\distr{}{}$ is now.  The distribution seems not to matter for
%correctness, at least for the schemes we consider.} \jnote{If instead we choose $S$ from ${\cal D}$, then
%is it clear we want to give $S$ to~$A$?} \tsnote{For \emph{correctness},
%yes, if for no other reason than to allow~$A$ to know when it asking
%a pointless query.  But also it will make no difference to the
%provable correctness of the constructions we consider.}
%\jnote{OK, I think I would just change the definitions so that the attacker
%chooses $S$.}
%(Unless stated otherwise, we assume security holds for all distributions and thus for all sets $S$.)
Adversary~$A$ is given~$\pubaux$~as input; it is also
provided with access to an oracle~$\TestOracle$ that, on input a query~$\qry \in \calQ$,
returns $\Qry(\pubaux,\privaux,q)$ and increments
a counter if this result is in error.  The adversary wins if it
manages to cause at least~$r>0$ such errors among its queries.
The notion can be lifted to the random-oracle model by providing
$\Rep,\Qry$ and the adversary~$A$ with oracle access to the
random-oracle(s).

%\jnote{I changed $\TestOracle$ so that it outputs $(a, q(S))$ rather
%than $(a,\mathrm{err})$. Note that the latter can be computed from the former,
%and in the general case I think the former is what we
%want.}\tsnote{This may have implications for the efficiency of
%reductions, I'm not sure. The reason I introduced the $\mathrm{err}$
%counter and returned this was to avoid~$A$ be forced to evaluate
%queries of unknown computational cost.} \jnote{Not sure what you mean. If the
%oracle returns $q(S)$ then $A$ doesn't have to evaluate it. All $A$ has to do
%is an equality check to see if $a=q(S)$ or not.}



\begin{figure}[htp]
\centering
\fpage{.65}{
\hpagess{.5}{.45}
{
\experimentv{$\ExpCorrect{\setprim,r}{A}$}\\
$S \getsr A$\\
$\mathcal{C} \gets \emptyset$; $\mathrm{err}\gets 0$\\
$(\pubaux,\privaux) \getsr \Rep(S)$\\
$\perp \getsr A^{\TestOracle}(\pubaux)$\\
if $\mathrm{err} < r$ then Return 0\\
Return 1
}
%
{
\oracle{$\TestOracle(\qry)$}\\
if $\qry \in \mathcal{C}$ then Return $\bot$\\
$a \gets \Qry(\pubaux,\privaux,\qry)$\\
if $a \neq \qry(S)$ then \\
\nudge $\mathrm{err}\gets\mathrm{err}+1$\\
$\mathcal{C} \gets \mathcal{C} \cup \{\qry\}$ \\
Return~$a$
}
}
\caption{Correctness of~$\Pi$ against an (adaptive) adversary~$A$.}
\label{fig:correctness}
\end{figure}

In this experiment we track the time complexity (relative to some
model of computation) and query complexity (i.e., number of
queries to $\TestOracle$) of~$A$.
We define the advantage of adversary~$A$ in the correctness experiment as
$\AdvCorrect{\Pi,r}{A} = \Prob{\ExpCorrect{\Pi,r}{A}=1}$.
Overloading notation, we write $\AdvCorrect{\Pi,r}{t,q}$ for the maximum over
all~$t$-time adversaries that ask at most~$q$ queries. We say a
data structure~$\Pi$ is $(t,q,r,\epsilon)$-correct if $\AdvCorrect{\Pi,r}{t,q} \leq \epsilon$.

\jnote{Note~$q$ is overloaded here.}

\todo{Explain that the case of $r=1$ does not necessarily imply anything for $r>1$: can have a scheme
where finding the first false positive is hard but then the rest are easy; can have
a scheme where finding one false positive is easy finding more is hard (e.g.,
because there do not exist
any more).}

\heading{Comparison to the Naor-Yogev definition.}
The structure of the Naor-Yogev definition is different from ours.
Lifting their definition\footnote{They focus specifically on set-representation data
structures
with no false negatives, and their data-structure syntax
does not distinguish public and private portions of the representation. Nevertheless, it is straightforward
to extend their definition to more closely match ours.}
to our setting,
the experiment is similar but the attacker
succeeds only if it outputs a (single) query $\qry$ for which
$\Qry(\pubaux,\privaux, \qry) \neq \qry(S)$  \emph{subject to the restriction that it did not
previously query $\qry$ to its $\TestOracle$ oracle}. We refer to
Figure~\ref{fig:NYcorrectness} for a definition of the relevant experiment.
We define the advantage of adversary~$A$ as
$\NYAdvCorrect{\Pi}{A} = \Prob{\NYExpCorrect{\Pi}{A}=1}$,
and write $\NYAdvCorrect{\Pi,r}{t,q}$ for the maximum over
all~$t$-time adversaries that ask at most~$q$ queries. We say that a
data structure~$\Pi$ is $(t,q,\epsilon)$-NY-correct if
$\NYAdvCorrect{\Pi}{t,q} \leq \epsilon$. \jnote{This should all probably
move to an appendix; it's a lot of notation to digest for something we never use again
in the paper.}

\jnote{Just noticed something (else) odd about the NY definition: we cannot assume w.l.o.g.\
that $A$ makes exactly $q$ queries, and in fact it is possible to have cases where increasing
the number of queries the attacker makes can decrease its advantage! This seems like
another drawback of the definition.}\tsnote{Really?  That seems worth
pointing out, as part of our list of complaints.}

\begin{figure}[htp]
\centering
\fpage{.6}{
\hpagess{.5}{.45}
{
\experimentv{$\NYExpCorrect{\setprim}{A}$}\\
$S \getsr A$\\
$\mathcal{C} \gets \emptyset$\\
%$\mathrm{err}\gets 0$\\
$(\pubaux,\privaux) \getsr \Rep(S)$\\
$\qry \getsr A^{\TestOracle}(\pubaux)$\\
if $\left(\qry \not \in \mathcal{C}\right.$ and \\
\nudge $\left.\Qry(\pubaux,\privaux,\qry) \neq \qry(S)\right)$ \\
\nudge \nudge then Return 1\\
Return 0
}
%
{
\oracle{$\TestOracle(q)$}\\
$a \gets \Qry(\pubaux,\privaux,q)$\\
$\mathcal{C} \gets \mathcal{C} \cup \{q\}$ \\
%\nudge $\mathrm{err}\gets\mathrm{err}+1$\\
Return~$a$
}
}
\caption{The Naor-Yogev definition of
correctness, adapted to our setting.}
\label{fig:NYcorrectness}
\end{figure}

With the above in place we can now relate their definition to ours.

\jnote{Do we have a compelling example of why the definition in Figure~\ref{fig:correctness}
is ``better'' than the definition in
Figure~\ref{fig:NYcorrectness}?}\tsnote{I don't know, but we do seem
to have a compelling list of shortcomings of their notion, which ours
doesn't seem to suffer. Anyway, it's a bit of an unfair comparison, in
their favor.  You're lifting their notion to ours, which is more
general.  And by the time we get to that, we have already done them
the favor of cleaning up the syntax, so that their ``lifted'' notion
looks better than it was.} \jnote{I agree, it's just that once we have ``lifted'' it
appropriately, it's not clear what's wrong with it and why we introduce a different
style of definition.}

\begin{theorem}
If $\Pi$ is $(t,q,\epsilon)$-NY-correct, then it is also
$(t, q', r, q'\epsilon/r)$-correct for any $q' \leq q+1$ and $r\geq
1$.
\end{theorem}
\begin{proof}
Let $\Pi$ be a data structure that is $(t,q,\epsilon)$-NY-correct,
and assume that for some $q' \leq q+1$ and
$r \geq 1$
there is an adversary $A$ running in time~$t$
and making $q'$ oracle queries such that
$\AdvCorrect{\Pi,r}{A} > q'\epsilon/r$.
(Note that
we may assume $A$ always makes exactly $q'$ queries without loss of generality.)
With probability at least
$q'\epsilon/r$ in an execution of $\ExpCorrect{\Pi,r}{A}$, we have that
$A$ makes at least $r$ distinct queries to $\TestOracle$ for which
an incorrect answer is returned. Let $A'$ be the algorithm that simply
runs~$A$, but chooses
uniformly one of the $q'$ queries of $A$ to its $\TestOracle$ oracle and outputs that query
as its final output. Then with probability at least $r/q' \cdot (q'\epsilon/r)=\epsilon$
the query chosen by $A'$
leads to an incorrect answer, and was not previously asked to the $\TestOracle$ oracle.
Since the running time of $A'$ is at most $t$, and it makes at most $q'-1 \leq q$ queries
to its oracle, this is a contradiction.
\end{proof}

\jnote{The above is tight, at least for $r=1$. Specifically, consider a scheme
in which every query is independently
answered incorrectly with probability~$\epsilon$. Such a
scheme will be $(t,q,\epsilon)$-NY-correct
for any $t, q$, however an adversary making $q=1/\epsilon$ queries has constant advantage
under our correctness definition (for $r=1$).}

\begin{theorem}
If $\Pi$ is $(t, q, 1, \epsilon)$-correct, then it is also $(t, q-1, \epsilon)$-NY-correct.
\end{theorem}

\begin{proof}
Let $\Pi$ be a data structure that is $(t,q,1,\epsilon)$-correct,
and assume
there is an adversary $A$ running in time~$t$
and making at most $q-1$ oracle queries such that
$\NYAdvCorrect{\Pi}{A} > \epsilon$.
Let $A'$ be the algorithm that simply
runs~$A$, passing the oracle queries of~$A$ to its own oracle, until~$A$ terminates
with output~$\qry$; then, $A'$ sends~$\qry$ to $\TestOracle$. It is immediate that $A'$ makes at most $q$ oracle queries, and
$\AdvCorrect{\Pi,1}{A'} \geq \NYAdvCorrect{\Pi}{A}$, a contradiction.
\end{proof}

\begin{theorem}
There exists a data structure $\Pi$ that
is $(t, q, 2, 0)$-correct, but is not $(t, 0, \epsilon)$-NY-correct
for any $\epsilon<1$.
\end{theorem}
\begin{proof}
Let $\Pi$ be the set-membership data structure in which $\Rep(S)$ outputs
$\pubaux=\privaux=S$, and
$\Qry(S, S, \qry_y)$ outputs $\qry_y(S)$ if $y \neq x$ but outputs $1-\qry_x(S)$ otherwise,
where $x \in {\cal X}$ is a fixed element of the universe. This
scheme always answers incorrectly for a single, fixed query, and answers
correctly for every other query. The theorem follows.
\end{proof}

\jnote{I'm not sure what to conclude from any of the results above. The proofs
are also all trivial.} \tsnote{Trivial or not, it's all part of the
overall contribution, which is putting this topic on a solid
foundation.  We can move it all to an appendix, but I still see it as
very worthwhile.} \jnote{It's worth having for completeness, I'm just not sure
what we (or the reader) is supposed to do with it. It's not like we can draw
any simple conclusions like ``our definition implies theirs'' or anything.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\leak}{{\sf leak}}
\subsection{Privacy}

One can also consider the orthogonal notion of \emph{privacy} for a
data structure.
We specialize to the case of set-membership data structures, and
focus on sets rather than multisets.
Before continuing, it will be useful to define a notion of ``point-wise min-entropy.''
Let ${\cal D}$ be
a distribution over subsets of some universe ${\cal X}$. The \emph{point-wise
min-entropy} of ${\cal D}$ is defined as
\[H_\infty({\cal D}) \bydef -\log \max_{x \in {\cal X}} \Pr[S \getsr {\cal D} : x \in S].\]



We formalize two types of privacy notions. The first captures
a ``one-wayness'' property that (informally) requires that
the public representation of a set~$S$ does not make it any easier for an attacker
to learn elements of~$S$.
The second definition
captures a flavor of semantic security, essentially requiring that $\pub$ does
not leak any information about the set~$S$ it represents beyond
what is captured by some explicit leakage function.

Our one-wayness notion is defined in Figure~\ref{fig:privacy-ow}.
The relevant experiment begins by first sampling a set $S$ according to a distribution
${\cal D}$. Then $\Rep(S)$ is run to obtain $\pubaux,\privaux$, and the attacker~$A$ is given
$\pubaux$. The attacker succeeds if it is able to output an element of~$S$.
We define the advantage of adversary~$A$ in this experiment\footnote{We
remark that one could consider augmenting experiment $\ExpPrivOW{\Pi,{\cal D}}{A}$ by additionally
giving $A$ access to an oracle for testing membership in~$S$. However, it is not hard
to see that allowing $q$ such queries can increase $A$'s advantage by at most a factor of~$q$.} as
$\AdvPrivOW{\Pi,\mathcal{D}}{A} = \Prob{\ExpPrivOW{\Pi,{\cal D}}{A}=1}$ and,
overloading notation, we write $\AdvPrivOW{\Pi,{\cal D}}{t}$ for the maximum of this value over
all~$t$-time adversaries.
Noting that an attacker can trivially succeed with probability
$2^{-H_\infty({\cal D})}$ by outputting the element most likely to be in~$S$,
we say a
set-representation data structure~$\Pi$ is $(t,\epsilon)$-ow-private if for all ${\cal D}$
we have $\AdvPrivOW{\Pi,{\cal D}}{t} - 2^{-H_\infty({\cal D})} \leq \epsilon$.
\jnote{Not sure I'm completely happy with the definition.}

\begin{figure}[hbtp]
\centering
\fpage{.25}{
%\hpagess{.5}{.45}
%{
\experimentv{$\ExpPrivOW{\setprim,\distr{}{}}{A}$}\\
$S \getsr \distr{}{}$\\
$(\pubaux,\privaux) \getsr \Rep(S)$\\
$z \getsr A(\pubaux)$\\
if $z \in S$ then return 1\\
return 0
%}
%{
%\oracle{$\TestOracle(q)$}\\
%Return $\Qry(\pubaux,\privaux,q)$
%}
}
\caption{Experiment for a ``one-way'' style privacy
  definition.}
\label{fig:privacy-ow}
\end{figure}


Our semantic-secure definition is simulation-based (see Figure~\ref{fig:privacy-ss}).
In this definition we compare the probabilities with which an attacker $A$ outputs~1
in two experiments: one ``real'' and one ``simulated.''
In the real experiment (ss-rep-1), $A$ outputs a set $S$  and is given the
public information $\pubaux$ that results from running $\Rep(S)$.
%\footnote{We do not give $A$ an oracle for issuing queries;
%since $A$ knows the set~$S$, such an oracle would be superfluous.
%\jnote{Interestingly,
%if we provided a query oracle in the real world and an oracle that returns the correct
%answer in the simulated world, then the definition seems to imply
%correctness also.}}
In the simulated experiment (ss-rep-0), $A$ outputs $S$ and is given $\pubaux$ output
by a simulator $\Sim$ that is only given ${\sf leak}(S)$ for some (possibly randomized)
function~${\sf leak}$.
For a given function ${\sf leak}$, adversary $A$, and simulator~$\Sim$,
we define the advantage
$\AdvPrivSS{\Pi,{\sf leak}}{A,\Sim} \bydef
\left| \Prob{\ExpPrivSSreal{\Pi}{A}=1} -
\Prob{\ExpPrivSSsim{\Pi,{\sf leak}}{A, \Sim}=1} \right|$.
Informally, a scheme $\Pi$ is secure with respect to some leakage function ${\sf leak}$
if for all $A$ there is a simulator $\Sim$ such that
$\AdvPrivSS{\Pi,{\sf leak}}{A,\Sim}$ is small.
Intuitively, this means that the public portion
$\pubaux$ of the representation of a set~$S$ leaks~${\sf leak}(S)$ and nothing more.
\jnote{The definition
as stated does not really work well in the presence of (programmable) random oracles.}

\begin{figure}[hbtp]
\centering
\fpage{.6}{
\hpagess{.5}{.45}
{
\experimentv{$\ExpPrivSSreal{\Pi}{A}$}\\
$S \getsr A$ \\
$(\pubaux,\privaux) \getsr \Rep(S)$\\
return $A(\pubaux)$\\
}
%
{
\experimentv{$\ExpPrivSSsim{\Pi, {\sf leak}}{A, \Sim}$}\\
$S \getsr A$\\
$\pubaux \getsr \Sim({\sf leak}(S))$ \\
return $A(\pubaux)$\\
}
}
\caption{Experiments for a ``semantic-security'' style privacy
  definition.}
\label{fig:privacy-ss}
\end{figure}


%
%\begin{figure}[htbp]
%\centering
%\hfpages{.495}
%{
%\hpagess{.49}{.49}
%{
%
%\experimentv{$\ExpPrivSSreal{\setprim,\distr{}{}}{A}$}\\
%$S\getsr \distr{}{}$\\
%$(M,\pubaux,\privaux) \getsr \Rep(S)$\\
%$(f,v) \getsr A^{\TestOracle}(M,\pubaux)$\\
%if $f(S)=v$ then\\
%\nudge Return 1\\
%Return 0\\
%
%\medskip
%\experimentv{$\ExpPrivSSsim{\setprim,\distr{}{}}{P}$}\\
%$S\getsr \distr{}{}$\\
%$(M,\pubaux,\privaux) \getsr \Rep(S)$\\
%$(f,v) \getsr P(\pubaux)$\\
%if $f(S)=v$ then\\
%\nudge Return 1\\
%Return 0\\
%}
%%
%{
%\oracle{$\TestOracle(q)$}\\
%$a \gets \Qry(M,\pubaux,\privaux,q)$\\
%Return~$a$\\
%}
%}
%{
%\hpagess{.49}{.49}
%{
%\experimentv{$\ExpPrivSS{\setprim,\distr{}{},P}{A}$}\\
%$S\getsr \distr{}{}$\\
%$b \getsr \bits$\\
%%$(M,\pubaux,\privaux) \getsr \Rep(S)$\\
%$(M_1,\pubaux,\privaux) \getsr \Rep(S)$\\
%$M_0 \getsr P(\pubaux)$\\
%%$(f,v) \getsr \getsr A^{\TestOracle}(M,\pubaux)$\\
%$b' \getsr A^{\TestOracle}(M_b,\pubaux)$\\
%%if $f(S)=v$ then\\
%if $b'=b$ then\\
%\nudge Return 1\\
%Return 0\\
%%
%%\medskip
%%\experimentv{$\ExpPrivSSsim{\setprim,\distr{}{}}{P}$}\\
%%$S\getsr \distr{}{}$\\
%%$(M,\pubaux,\privaux) \getsr \Rep(S)$\\
%%$(f,v) \getsr P(\pubaux)$\\
%%if $f(S)=v$ then\\
%%\nudge Return 1\\
%%Return 0\\
%}
%%
%{
%\oracle{$\TestOracle(q)$}\\
%$a \gets \Qry(M_1,\pubaux,\privaux,q)$\\
%Return~$a$\\
%}
%}
%\caption{Semantic-security style privacy
%  definitions. \textcolor{red}{On the left, need to protect against
%    adversary outputting
%    things like $f(S)=M$.  One idea is to forbid~$f$ such that
%    $f(S)=f(S')$ for all $S,S'$ in the support of $\distr{}{}$.}
%    }
%\label{fig:privacy-ss}
%\end{figure}

\heading{Relationships between the notions.}
Our intuition is that semantic security implies one-wayness. And, indeed, this is
the case---provided one is careful with the technical details.
For a distribution ${\cal D}$
over subsets of some universe ${\cal X}$, define
\[\tilde H_\infty({\cal D} \mid {\sf leak}) \bydef -\log \sum_{r \in R} \Pr_{S \getsr {\cal D}}[{\sf leak}(S)=r] \cdot
\max_{x \in {\cal X}} \Pr_{S \getsr {\cal D}}[x \in S \mid {\sf leak}(S)=r].\]

\begin{theorem}
Let $\Pi$ be a set-representation data structure that is $(t, \epsilon)$-semantically secure
with respect to leakage ${\sf leak}:2^{\cal X} \rightarrow R$.
Then $\AdvPrivOW{\Pi,\mathcal{D}}{t} \leq 2^{-\tilde H_\infty({\cal D} \mid {\sf leak})} + \epsilon$.
\end{theorem}
\begin{proof}
Fix a distribution ${\cal D}$ and an attacker
$A$ running in time $t$, and let $\delta \bydef \AdvPrivOW{\Pi,\mathcal{D}}{A}$.
Define an attacker $A'$ who behaves as follows: first, it samples a set $S$ according to
distribution~${\cal D}$. Then, given $\pubaux$, it runs $A(\pubaux)$ to obtain an element~$z$.
Finally, it outputs~1 if and only if $z \in S$.

It is immediate that $\Pr[\ExpPrivSSreal{\Pi}{A'}=1] = \delta$. Semantic
security of $\Pi$ implies that there exists a simulator $\Sim$ for which
$\ExpPrivSSsim{\Pi, {\sf leak}}{A', \Sim} \geq \delta - \epsilon$. However,
the only information
that $\Sim$
and $A'$ jointly have about the set~$S$ that was sampled is ${\sf leak}(S)$; thus,
we must have $\ExpPrivSSsim{\Pi, {\sf leak}}{A', \Sim} \leq 2^{-\tilde H_\infty({\cal D} \mid {\sf leak})}$.
This implies
$\delta \leq 2^{-\tilde H_\infty({\cal D} \mid {\sf leak})}+\epsilon$ as desired.
\end{proof}

%\todo{SS$\Rightarrow$OW?
%  (Probably not in general, but perhaps for set-multiplicity data
%  structures that satisfy certain assumptions on the qnuery set.)
%  SS$\not\Rightarrow$ correctness; the converse is already shown by
%  the example I gave earlier, i.e. $M=S\setminus\{x\}$ for random $x
%  \in S$.} \jnote{Since we can set $\pubaux$ to be the emptystring, I think
%  it is trivial to see that privacy does not imply correctness.}
