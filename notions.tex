\section{Security Notions}
\label{sec:security-notions}
\tsnote{intro text}
Following NY, we are interested in defining an adaptive (i.e.,
adversarial) notion of correctness.   
In addition to correctness, we establish three notions of privacy for
set-representations. The first two have the flavor of a one-wayness game, in which the adversary is given the auxiliary information~$\pubaux$ and, either the representation~$M$ or the abillity to call an oracle that evaluates $\Qry(M,\pubaux,\privaux,q)$ on queries~$q$ of its choosing.  At the end of this game, the adversary must output some point in the set represented by~$M$.  In the second privacy notion, the adversary presents two sets~$S_0$ and $S_1$ (of equal size) and a representation~$M$ is created for one of these two. Then the adversary is given $\pubaux$ and oracle access to $\Qry(M,\pubaux,\privaux,q)$, and it must decide which set~$M$ represents.

\subsection{Correctness Against Adaptive Adversaries}

First, a set~$S$ is chosen according to some
distribution~$\distr{\calS}{}$ over the collection of multisets
$\mathcal{S}$ associated to~$\Pi$, and then
$\Rep(S)$ is run to generate $(M,\pubaux,\privaux)$.
%(Unless stated otherwise, we assume security holds for all distributions and thus for all sets $S$.)
Adversary~$A$ is given~$\calS$ and $\pubaux$~as input; it is
provided an oracle~$\TestOracle$ that, on input a query~$q \in \calQ$,
computes (and returns) the result of $\Qry(M,\privaux,q)$, and increments
a counter if this result is in error.  The adversary wins if it
manages to cause at least~$r>0$ such errors among its queries.

The notion is lifted to the random-oracle model by providing
$\Rep,\Qry$ and the adversary~$A$ with oracle access to the
random-oracle(s).



\begin{figure}[htp]
\centering
\fpage{.6}{
\hpagess{.6}{.35}
{
\experimentv{$\ExpCorrect{\setprim,\distr{\calS}{},r}{A}$}\\
$S \getsr \distr{\calS}{}$\\
$\mathrm{err}\gets 0$\\
$(M,\pubaux,\privaux) \getsr \Rep(S)$\\
$z \getsr A^{\TestOracle}(S,\pubaux)$\\
if $\mathrm{err} < r$ then Return 0\\
Return 1
}
%
{
\oracle{$\TestOracle(q)$}\\
$a \gets \Qry(M,\pubaux,\privaux,q)$\\
if $a \neq q(S)$ then \\
\nudge $\mathrm{err}\gets\mathrm{err}+1$\\
Return~$(a,\mathrm{err})$
}
}
\caption{Correctness of~$\Pi$ against (adaptive) adversary~$A$, when
  the target multiset~$S$ is sampled from~$\calS$ according to distribution~$\distr{\calS}{}$.} 
\label{fig:correctness}
\end{figure}

In this experiment we track the time-complexity (relative to some
implied model of computation) and query-complexity (i.e., number of
queries) of the adversary~$A$.  
We define the advantage of adversary~$A$ in the correctness experiment as 
$\AdvCorrect{\Pi,\distr{\calS}{},r}{A} = \Prob{\ExpCorrect{\Pi,\distr{\calS}{}, r,}{A}=1}$.
Overloading notation, we write $\AdvCorrect{\Pi,\distr{\calS}{},r}{t,q}$ for the maximum over all~$t$-time adversaries that ask at most~$q$ queries. Roughly, we say that a
set-representation~$\Pi$ is $(t,q,r,\epsilon')$-correct if $\AdvCorrect{\Pi,\distr{\calS}{},r}{t,q} \leq \epsilon'$.  




%
%And if the experiment requires the adversary to induce~$r$ errors, the attack wins iff
%$N \stackrel{{\rm def}}{=} \sum_{i=1}^T X_i \geq r$.  Modelling the $X_i$ as independent Bernoulli trials with
%probability~$\epsilon$ gives $N$ a binomial distribution.  \fixme{Something feels wrong with this...}  
%Writing $\bin(T, \epsilon; r)$ for the probability that $N \geq r$,
%we conclude that the \emph{best} correctness we can hope for against adversaries making~$T$ queries is  $\bin(T,\epsilon; t))$. %\jnote{Need to find different terms to use for a query $q \in \mathcal{Q}$
%and a query that the attacker makes to its oracle.}
%\tsnote{Viewed another way, we could let~$T$ be a negative binomial RV, and ask how many queries are needed (w.h.p) for $N \geq t$.} 
%
%\jnote{One option is to define the adversary's \emph{advantage} as the difference between
%its success probability and the success probability of the above,
%trivial attack. Just a thought.}
%\tsnote{Or, perhaps by recasting security
%  as distinguishing between $\Qry(M,\aux,\cdot)$ and an oracle that
%  returns 0,1 according to Bernoulli with paramter~$\epsilon$.}
%\fixme{Not clear this attack is generically applicable enough to serve as a reference/baseline.  (See email discusssion 7/23.)  Might be worth pointing out that this intuition, between non-adaptive error-probability and the expected number of queries to find an error, can be quite misleading.}

\heading{Comparison to Naor-Yogev definition.}
The style of the Naor-Yogev (NY) definition is slightly different. \jnote{Even if we ignore
all the other issues, chief among them the inconsistent way it treats the hash functions.}
Lifting their definition to our setting, the experiment is similar but the attacker
succeeds only if it outputs a single query $q$ for which $\Qry( M,
\aux, q) \neq q(S)$  \emph{subject to the restriction that it did not query $q$ to its $\Qry$ oracle}.
It will be interesting to understand formally the relation between our definition and theirs.
Here are some observations:
\begin{enumerate}
\item Say a scheme is $\epsilon_{NY}$-secure under the NY definition.
Then we claim it is $(t,q, r, q\epsilon_{NY}/r)$-correct. To see
this, assume not. Then there is a $t$-time attacker~$A$ that, with
probability at least $\epsilon'=q\epsilon_{NY}/r$,
issues~$q$ Test-queries of which at least~$r$ cause errors. If we simply run~$A$ and then choose a random Test-query to
output, we succeed with probability at least $\epsilon' \cdot r/q$. It is unclear whether this is tight.

\item There is a contrived scheme that is $(t, q, 2, 0)$-correct but not NY-secure at all; the basic idea is
to have a set-representation that always has \emph{exactly one} false positive that is easy to find
given the public information.

\item If a scheme is $(t,q,1,\epsilon)$-correct, then it is also $\epsilon$-secure under the NY definition,
at least for attackers making at most $q-1$ queries.
This is immediate.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Notions of Privacy}
One can also consider the orthogonal notion of privacy for a
set-representation.  We formalize two types of privacy notions. One
type captures a kind of one-wayness of the representation~$M$,
relative to the allowed queries.  Informally, that given the
representation and the public information, it is hard to guess any
value in the represented set~$S$.  The other type captures a kind of
semantic security, essentially requiring that $(M,\pub)$ and th
allowed queries do not leak any (non-trivial) information about the set~$S$.
%\jnote{Actually, I am now unsure what the right way to define it is. It seems natural
%to give the attacker $\aux$. But if we give them $\aux$ and $M$ then they have everything.
%If $S$ has high min-entropy (element-wise), then it might still be
%possible to have security here.}\tsnote{I think we will always bump up
%against the (element-wise) min-entropy of the distribution over~$S$,
%at least in the ``one-wayness'' style definition that I had been imagining. }

In Figure~\ref{fig:privacy-ow} we give two ``one-wayness''
definitions, in which the adversary must output an element of the
set~$S$ represented by~$M$.  The first version (priv) gives the
adversary~$(M,\pubaux)$ as input; the second (wpriv) gives
only~$\pubaux$.  The wpriv-notion captures leakage about the elements
of~$S$ that results from observing the results of allowed queries.
The stronger priv-notion captures what is jointly leaked, by the
representation~$M$ and the allowed queries, about set elements.  We
define advantage measures $\AdvPriv{\Pi,\distr{\calS}{}}{A} =
\Prob{\ExpPriv{\Pi,\distr{\calS}{}}{A}=1}$ and $\AdvWPriv{\Pi,\distr{\calS}{}}{A} =
\Prob{\ExpWPriv{\Pi,\distr{\calS}{}}{A}=1}$; in both we track the
time-complexity~$t$ and number of oracle queries~$q$ made by the adversary.

\tsnote{Still messing about here, and in the figure.}
In Figure~\ref{fig:privacy-ss} we give a definition capturing semantic-security (of sets)
with respect to the full representation (ss-rep).  In the ``real''
setting (ss-rep-1), a set~$S$ is sampled according to distribution~$\distr{\calS}{}$,
and the adversary is given the~$M,\pubaux$ that result from running
$\Rep(S)$.  It is also provided oracle access to $\TestOracle$.
The adversary must output a function~$f\colon\calS \to \bits^*$ and a
string~$v$ such that $f(S)=v$.  In the ``fake'' setting (ss-rep-0) a
predictor~$P$ is given $\pubaux$ only, and no $\TestOracle$ access.  It
also outputs an $f,v$ pair such that $f(S)=v$.  The advantage of~$A$ (over~$P$)
is $\AdvPrivSS{\Pi,\distr{\calS}{}}{A,P} =
\Prob{\ExpPrivSSreal{\Pi,\distr{\calS}{}}{A}=1} -
\Prob{\ExpPrivSSsim{\Pi,\distr{\calS}{}}{P}=1}$.  To prevent trivial wins
for~$A$, e.g. $f(S)=M$, we forbid~$A$ from outputting~$f$
such that $f(S)=f(S')$ for all $S,S'$ in the support of $\distr{\calS}{}$.


\begin{figure}[htbp]
\centering
\fpage{.495}{
\hpagess{.5}{.45}
{
\experimentv{$\ExpPriv{\setprim,\distr{\calS}{}}{A}$}\\
$S \getsr \distr{\calS}{}$\\
$(M,\pubaux,\privaux) \getsr \Rep(S)$\\
$z \getsr A^{\TestOracle}(M,\pubaux)$\\
if $z \in S$ then Return 1\\
Return 0\\

\medskip
\experimentv{$\ExpWPriv{\setprim,\distr{\calS}{}}{A}$}\\
$S \getsr \distr{\calS}{}$\\
$(M,\pubaux,\privaux) \getsr \Rep(S)$\\
$z \getsr A^{\TestOracle}(\pubaux)$\\
if $z \in S$ then Return 1\\
Return 0\\
}
%
{
\oracle{$\TestOracle(q)$}\\
$a \gets \Qry(M,\pubaux,\privaux,q)$\\
Return~$a$
}
}
\caption{``One-wayness'' style privacy
  definitions. The bottom is a weaker notion, because the representation
  is hidden from the adversary.} 
\label{fig:privacy-ow}
\end{figure}

%
\begin{figure}[htbp]
\centering
\hfpages{.495}
{
\hpagess{.49}{.49}
{

\experimentv{$\ExpPrivSSreal{\setprim,\distr{\calS}{}}{A}$}\\
$S\getsr \distr{\calS}{}$\\
$(M,\pubaux,\privaux) \getsr \Rep(S)$\\
$(f,v) \getsr A^{\TestOracle}(M,\pubaux)$\\
if $f(S)=v$ then\\
\nudge Return 1\\
Return 0\\

\medskip
\experimentv{$\ExpPrivSSsim{\setprim,\distr{\calS}{}}{P}$}\\
$S\getsr \distr{\calS}{}$\\
$(M,\pubaux,\privaux) \getsr \Rep(S)$\\
$(f,v) \getsr P(\pubaux)$\\
if $f(S)=v$ then\\
\nudge Return 1\\
Return 0\\
}
%
{
\oracle{$\TestOracle(q)$}\\
$a \gets \Qry(M,\pubaux,\privaux,q)$\\
Return~$a$\\
}
}
{
\hpagess{.49}{.49}
{
\experimentv{$\ExpPrivSS{\setprim,\distr{\calS}{},P}{A}$}\\
$S\getsr \distr{\calS}{}$\\
$b \getsr \bits$\\
%$(M,\pubaux,\privaux) \getsr \Rep(S)$\\
$(M_1,\pubaux,\privaux) \getsr \Rep(S)$\\
$M_0 \getsr P(\pubaux)$\\
%$(f,v) \getsr \getsr A^{\TestOracle}(M,\pubaux)$\\
$b' \getsr A^{\TestOracle}(M_b,\pubaux)$\\
%if $f(S)=v$ then\\
if $b'=b$ then\\
\nudge Return 1\\
Return 0\\
%
%\medskip
%\experimentv{$\ExpPrivSSsim{\setprim,\distr{\calS}{}}{P}$}\\
%$S\getsr \distr{\calS}{}$\\
%$(M,\pubaux,\privaux) \getsr \Rep(S)$\\
%$(f,v) \getsr P(\pubaux)$\\
%if $f(S)=v$ then\\
%\nudge Return 1\\
%Return 0\\
}
%
{
\oracle{$\TestOracle(q)$}\\
$a \gets \Qry(M_1,\pubaux,\privaux,q)$\\
Return~$a$\\
}
}
\caption{Semantic-security style privacy
  definitions. \textcolor{red}{On the left, need to protect against
    adversary outputting
    things like $f(S)=M$.  One idea is to forbid~$f$ such that
    $f(S)=f(S')$ for all $S,S'$ in the support of $\distr{\calS}{}$.}
    } 
\label{fig:privacy-ss}
\end{figure}
\subsection{Relationships Among Notions}

\heading{Privacy notions. }
Clearly we have priv $\Rightarrow$ wpriv, tightly and by a simple
reduction.  We should be able to show
\begin{itemize}
%\item ss-rep $\Rightarrow$ ind-qry
%\item ind-qry $\Rightarrow$ ss-rep \tsnote{Not sure about this separation...}
\item ss-rep $\Rightarrow$ priv \emph{for set-multiplicity data
    structures} \tsnote{but probably not in general}
\item \{w\}priv $\not\Rightarrow$ ss-rep
\item wpriv $\not\Rightarrow$ priv \tsnote{$M=S$, or my
    $M=S\setminus \{x\}$ for a random $x\in S$, if you want something
    a bit less trivial. I'm sure there are more natural schemes that
    will separate, too.}
\end{itemize}


\heading{Correctness vs.\ Privacy. }
If we allow for trivial schemes, e.g. $M=S$, then correctness and the stronger version of one-wayness privacy (Priv) are clearly orthogonal.
\tsnote{My $M=S\setminus\{x\}$ for a random $x \in S$ construction is less trivial (it compresses), but also serves to separate correctness from Priv.}
\tsnote{In general, it isn't clear how to reduce
correctness to the Priv notion.  In the correctness experiment, you
  get~$(S,\aux)$ but not~$M$; whereas in the Priv-notion, the
  adversary expects~$(M,\aux)$ as input.  Unless the coins of Rep are
  effectively leaked in~$\aux$, you can't reliably produce~$M$
  given~$(S,\aux)$.} 
Curiously, $M=S$ does seem to be both correct and private (up to the element-wise min-entropy of~$S$) in the weaker version of one-wayness privacy (wPriv).
\tsnote{Reducing correctness to the weaker version, wPriv, is syntactically possible, but not clear how to connect the success events.  In the one-wayness game, you win by outputing an element of~$S$; but how does this lead to finding an error-inducing query?  Maybe the one-wayness attacker makes no queries, and just outputs a point~$z$.  Then the correctness attacker does what?  Ask some query~$q_z$ related to~$z$ ---remember, queries are not syntactically restricted to set membership!--- and see if the oracle returns the true value $q_z(S)$?  This is pretty complicated... and it's not clear how to do a quality reduction.   }


\tsnote{Likewise the other way: the one-wayness adversary does not get~$S$, and yet needs to provide this to the correctness adversary.}

