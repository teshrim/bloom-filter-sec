\section{Secure Set Representation, Abstractly}
We focus on the case of static set-representations only (for now).
\def\pub{{\sf pub}}
\def\aux{{\sf aux}}

\subsection{Syntax}
Fix a universe $U$.

\begin{definition} %\tsnote{We need a more descriptive name than ``data structure'' :)}
A (randomized) \emph{set-representation primitive} is a pair of algorithms $(\Rep, \Qry)$
parameterized by a collection $\mathcal{S}$ of subsets of~$U$ and a collection
of supported queries $\mathcal{Q}=\{q \colon \mathcal{S} \to \mathbb{R}\}$, where:
\begin{itemize}
\item $\Rep$ is a randomized algorithm taking as input $S \in \mathcal{S}$,
and outputting a pair of values $(M,\aux)$, the \emph{representation} (of~$S$) and the \emph{auxillary information} (of~$M$).
\item $\Qry$ is a deterministic algorithm that takes as input $M, \aux$,
and a query $q\in \mathcal{Q}$, and returns value~$a$.
\end{itemize}
A data structure is \emph{$\epsilon$-correct} if for all $S \in \mathcal{S}$ and
all $q \in \mathcal{Q}$ it holds that
\begin{eqnarray}
\Pr[(M,\aux) \getsr \Rep(S) : \Qry(M, \aux, q) \neq q(S)] \leq \epsilon, \label{eqn:correctness}
\end{eqnarray}
%where $q(S)$ denotes the correct answer to the query $q$ on the set~$S$.
The \emph{size} of a data structure is the maximum (bit)length of any~$M$ that can be
output by $\Rep$.
\end{definition}

Our treatment of $M,\aux$ is not symmetric, since we only count $M$ against the size
of the set-representation. When we define security
we may give the attacker $\aux$ but not~$M$, and in that case the set-representation cannot
trivially make everything part of~$\aux$. \tsnote{Encoding secrets into~$M$ may cause some headaches in
  the security definitions; we'll see. }
%\tsnote{By the way, I'm coming around to the
%  viewpoint that it is fair to include in the ``size'' of the
%  representation any secret information.  In makes more difficult
%  comparisons to classical lower-bounds (which [NY] makes, incorrectly
% IMO), but it does seem fair to say ``this is how many bits of memory
% you need to allocate to represent this set \emph{securely}.''}

The above definition can be lifted to the random-oracle model in the natural way
by giving $\Rep, \Qry$ access to a random oracle. In that case,
the probability in Equation~(\ref{eqn:correctness})
is also taken over choice of the random oracle.

\heading{Examples.}
It is not hard to see Bloom filters are one possible instantiation of the above. If we fix some
size bound~$n$, then $\mathcal{S}$ becomes the collection of all subsets of $U$
of size (at most)~$n$. We also fix $\mathcal{Q} = U$, where a query ``$x$'' has
the semantics ``is $x$ in $S$?'' Algorithm $\Rep$, which has values $k, m$ hardwired,
chooses a set of hash functions $h_1, \ldots, h_k$ and computes an $m$-bit
array in the usual way; a natural possibility is to set $\aux = (h_1, \ldots, h_k)$ and
to let~$M$ be the bit array.  
%\tsnote{If $\mathcal{Q}=U$ and we use the
%  semantics you suggest, then isn't Equation~\ref{eqn:correctness}
%  both correctness and soundness?  If so, I don't see how this
%  captures the classical BF, which requires $\epsilon=0$ for one kind
%  of error, but allows $\epsilon>0$ for the other. } 
%\jnote{The definition does not distinguish
%  between elements in the set (for which $q(S)=1$) or outside the set (for which
%  $q(S)=0$). But a Bloom filter does satisfy Equation~\ref{eqn:correctness} in either case.}
%  \jnote{In that sense, I am using ``soundness'' and ``correctness'' interchangeably here.}
  \jnote{I'm not tied to allowing false negatives when we specialize the definition to the case
  of set-membership queries. But in the abstract definition it seems unclear why one would choose
  some queries on which error is ok and other queries where error is not allowed. Though if one
  wanted to be general, one could simply have two (disjoint) sets of queries $\mathcal{Q}_1, \mathcal{Q}_2$
  where error is allowed on the former but not on the latter.}

\subsection{Adversarial Soundness}
\heading{FP security.}
As highlighted by Naor and Yogev,
Equation~(\ref{eqn:correctness}) is a non-adaptive version of correctness;
we are interested in defining an adaptive (i.e., adversarial) notion
of correctness. \tsnote{Correctness?  Or soundness?}
The general style of the definition is as follows:
first, a set $S$ is chosen according to some distribution over~$\mathcal{S}$ and then
$\Rep(S)$ is run to generate $(\aux, M)$. (Unless stated otherwise, we assume
security holds for all distributions and thus for all sets $S$.)
The attacker $A$ is given $\aux$ and (possibly)~$S$;
in addition, $A$ is given \emph{oracle access} to~$\Qry(\aux, M, \cdot)$.
If $(\Rep, \Qry)$ is defined in the random-oracle model, then
$A$ is given access to the random oracle as well.
$A$ \emph{succeeds} if it outputs $t$ distinct queries $q_1, \ldots, q_t \in \mathcal{Q}$ for which
$\Qry(\aux, M, q_i) \neq q_i(S)$ for all~$i$.
Roughly, we say that a data structure is $(t,\epsilon')$-FP-secure if the probability that
any polynomial-time attacker succeeds is at most~$\epsilon'$. A full definition
would also bound the number of queries to $\Qry$ (and the random oracle) made
be the attacker; it is useful to make the convention that if $A$ outputs
$q_1, \ldots, q_t$ then it must have made those queries to its oracle previously.

The notion of FP-security defined above captures the fp-prv notion for Bloom filters
if we put the hash
functions in $M$ (and thus increase the size of the data structure); it also captures the fp-pub
notion if we put the hash function in~$\aux$. \tsnote{Except that the win condition allows both
false-positives and false-negatives, given the correctness requirement
in the syntax.} \jnote{True. But if false negatives cannot occur at all (by design of
the data structure, not by definition of the primitive), then the attacker cannot hope to win
by finding a false negative.} It captures the fp-bb-pub notion in the
random-oracle model.

Note that the security we can hope for is somewhat limited, since there
is always a trivial attack in which
the attacker tries random queries $q_1, q_2, \ldots$ until it finds $t$ queries for which the
data structure returns an incorrect answer.\footnote{This assumes the attacker
knows the true set $S$, which need not be the case.} Roughly speaking,
if the data structure is $\epsilon$-correct then the attacker expects to find a query on which
an incorrect result is returned
every $1/\epsilon$ tries; thus, an
attacker making $t/\epsilon$ queries succeeds with constant probability.

\def\bin{{\sf Bin}}

Actually, it seems worthwhile to formalize this. Let $X_i$ be a random variable indicating
whether the $i$th query of the attacker gives an incorrect result. Then an attacker making $T$
queries can succeed
if $N \stackrel{{\rm def}}{=} \sum_{i=1}^T X_i \geq t$. If we treat the $X_i$ as independent Bernoulli trials with
probability~$\epsilon$, then $N$ follows the well-studied binomial distribution.
Let $\bin(T, \epsilon; t)$ denote the probability that $N \geq t$. So the best security we can
hope for
is that if the data structure is $\epsilon$-correct then for any desired bound $T$
the data structure is $(t, \bin(T,\epsilon; t))$-FP-secure against any attacker making
at most $T$~queries. \jnote{Need to find different terms to use for a query $q \in \mathcal{Q}$
and a query that the attacker makes to its oracle.}

\jnote{One option is to define the adversary's \emph{advantage} as the difference between
its success probability and the success probability of the above,
trivial attack. Just a thought.}
\tsnote{Or, perhaps by recasting security
  as distinguishing between $\Qry(\aux,M,\cdot)$ and an oracle that
  returns 0,1 according to Bernoulli with paramter~$\epsilon$.}

\heading{Comparison to Naor-Yogev definition.}
The style of the Naor-Yogev (NY) definition is slightly different. \jnote{Even if we ignore
all the other issues, chief among them the inconsistent way it treats the hash functions.}
Lifting their definition to our setting, the experiment is similar but the attacker
succeeds only if it outputs a single query $q$ for which $\Qry(\aux, M, q) \neq q(S)$ \emph{subject
to the restriction that it did not query $q$ to its $\Qry$ oracle}.
It will be interesting to understand formally the relation between our definition and theirs.
Here are some observations:
\begin{enumerate}
\item Say a scheme is $\epsilon_{NY}$-secure under the NY definition.
Then we claim it is $(t, T\epsilon_{NY}/t)$-secure against an attacker making $T$ queries. To see
this, assume not. Then there is an attacker $A$ that, with probability $\epsilon'=T\epsilon_{NY}/t$,
issues $T$ queries of which at least $t$ among those give incorrect answers.
If we simply run $A$ and
then choose a random query to output, we succeed with probability at least $\epsilon' \cdot t/T$.
It is unclear whether this is tight.

\item There is a contrived scheme that is $(2, 0)$-FP-secure but not NY-secure at all; the basic idea is
to have a data structure that always has \emph{exactly one} false positive that is easy to find
given the public information.

\item If a scheme is $(1,\epsilon_{FP})$-FP-secure for an attacker making $T$ queries
then it is also $\epsilon_{FP}$-secure under the NY definition,
at least for attackers making at most $T-1$
queries.
This is immediate.
\end{enumerate}

\subsection{Privacy}
One can also consider the orthogonal notion of privacy for a data structure.
\jnote{Actually, I am now unsure what the right way to define it is. It seems natural
to give the attacker $\aux$. But if we give them $\aux$ and $M$ then they have everything.
If $S$ has high min-entropy (element-wise), then it might still be
possible to have security here.}\tsnote{I think we will always bump up
against the (element-wise) min-entropy of the distribution over~$S$,
at least in the ``one-wayness'' style definition that I had been imagining. }
There are several possible definitions:
\begin{enumerate}
\item A ``one-wayness'' definition where $S$ has high min-entropy (element-wise), and we
give the attacker $\aux$ and either $M$ or oracle access to $\Qry$. The attacker
succeeds if it can output an element in~$S$.

\item An ``indistinguishability'' definition where either $S_0$ or $S_1$ is used, and the attacker
must determine which. Here the attacker is given $\aux$ but only oracle access to $\Qry$, and
it is disallowed from asking any query $q$ for which $q(S_0) \neq
q(S_1)$. \tsnote{How will the adversary know that a query satisfies
  this in (say) the case of the classical BF?  We can, of course,
enforce it in the experiment, but then our resource accounting risks
overcounting the number of queries.} \jnote{I was assuming the attacker knows $S_0, S_1$.}
\tsnote{Also, we need that, in general, $\aux$ itself
does not leak information about~$S_0$ vs.\ $S_1$. } \jnote{Sure, this would be implied
by the definition in this case.}
\end{enumerate}
