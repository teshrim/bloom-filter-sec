\section{Security Notions for Hash-Based Filters}

\heading{FP-security of hash-based filters.}  
%\tsnote{NY give it in the private hash setting (sort of); but, intuitively, it should be hard to find false-positives even if you know that MD5 or SHA-x are the hash functions.  Not totally sure how to capture this intuition nicely.}
%
%\jnote{Not sure I agree. First of all, if $\epsilon$ is not negligible then a random element is a false positive with noticeable probability. Beyond that, I think that intuitively it makes sense that if you want false positives to be hard to find then you need to make the hash functions secret.} 
%
%\tsnote{I don't think it makes sense to talk about asymptotics or negligibility, for exactly the reason you state. I think the key point here is: what is ``hard''? The designer decides what FP rate is acceptable for a given application, a given set of efficiency constraints, the side-effects of a FP, etc.  For a fixed FP target, she optimizes the filter size and/or the number of hash functions for her setting. Whether the target FP rate is 0.01 or $2^{-80}$, we should be able to say (in the ROM, at least) that it will take this-many hash computations, and this many on-line set-membership queries, to find the first FP.  In the standard model, with public hash functions, it is clearly more difficult to make formal claims.  Even so, in practice I expect it would be quite expensive to find a string~$x$ such that $(h_1(x),h_2(x),\ldots,h_k(x))$ falls in a given set of tuples when $h_i(x)=\mathrm{truncate}(\mathrm{SHA256}(\langle i \rangle \concat x), m)$, say. (Even more so if my setting admits relatively expensive hash computations, e.g. SCRYPT.) BTW, your suggestion to have a FP notion with secret~$\mathcal{S}$ is interesting here. }
%
The traditional notion of soundness for a Bloom filter captures the difficulty of finding false positives when the attacker is non-adaptive. Following NY, we consider soundness against adaptive adversaries. But we further generalize to allow for settings in which the attacker may have some a priori knowledge about the contents of~$\calS$. (The Niedermaier et al.~\cite{xxx} attacks, for example, exploit knowledge about the distribution of German last names.) In particular, our notions take as input an explicit distribution $\distr{U}{n}$ over~$[U]^n$.

%\jknote{We also want to capture the fact that finding the first false positive should not make it any easier to find subsequent false positives. This is not really captured by the Naor paper, either (at least not directly, though it may end up being implied by their definition).} 
%
%\tsnote{See my comment in the intro.}

In Figure~\ref{fig:fp-filter} we give three distinct notions, characterized by what access the adversary has to the underlying hash functions used by the filter.  In the top notion, the hash functions are secret.  This is the setting addressed by NY, and it captures applications in which the hash functions are (say) secretly keyed PRFs, and in which no explicit, external interface to these is surfaced.
%
The bottom notion considers the case that the full code of the hash functions is known to the attacker.  This is the case, for example, when attacking the Bloom filters used in the Squid proxy~\cite{xxx}.
%
The middle notion is a compromise: it makes the hash functions public, but assumes that the adversary only accesses them in a black-box manner.  That is, the adversary does not exploit structural features of the hash functions in its attack.  This notion makes it easy to track the query complexity of an attack, and also allows us to capture constructions in the random-oracle model. \tsnote{This is the setting for the Neidermayer et al.\  attacks.  It's also the setting for ROM attacks.}

For each experiment, we define an associated advantage
notion.  Namely, given an $(n,k,m)$-filter~$B=(\Hash,\Rep,\Qry)$,
distribution~$\distr{U}{n}$ and adversary~$A$, we define:
\begin{align*}
\AdvFPSecHash{B}{\distr{U}{n},A} &= \Prob{\ExpFPSecHash{B}{\distr{U}{n},A}} \\
\AdvFPPubHashBB{B}{\distr{U}{n},A} &= \Prob{\ExpFPPubHashBB{B}{\distr{U}{n},A}} \\
\AdvFPSecHash{B}{\distr{U}{n},A} &= \Prob{\ExpFPPubHash{B}{\distr{U}{n},A}}
\end{align*}
The probabilities are over the coins of the indicated experiment,
and the coins of the adversary.   In all experiments, we track the
time-complexity~$t$ of~$A$, as well as the number of set-membership
($\QryOracle$ oracle) queries~$q_{\mathrm{sm}}$ that it makes.   In
the second, we also track the number of hash-queries
$q_{\mathrm{h}}$ that the adversary makes.

\jnote{7/8: Do our definitions imply the Naor definition? If so, then why do they use a PRP in their construction?}

We note that the distribution~$\distr{U}{n}$ must be independent of the hash functions $h_1,h_2,\ldots,h_k$ that are used to create~$M$.  Otherwise, when (say) $\Sigma=\bits$, the distribution may only assign positive probability to sets~$\calS$ that cause an abnormally large number of bits in~$M$ to be set to 1.  Our security notions enforce this independence.

\jnote{How do we want to define a ``secure'' Bloom filter (even informally)? Do we want to say that the probability of finding a false positive is negligible? Or that if we set the FP rate to $\epsilon$ then the best an attacker can do with $q$ hash queries is $1-(1-\epsilon)^q$ plus negligible?}
%
\tsnote{Formally, I don't think we can (and still be rooted in reality).  Even informally it's hard, since the fact is that the designer decides what is ``secure'' for her setting.  I think we just say something like ``A bloom filter is $(t,q_h,q_m,\epsilon)$-secure if no attacker running in time at most~$t$, asking at most~$q_h$ hash queries and $q_m$ set-membership queries, has probability more than~$\epsilon$ of finding a FP.'' (If you like, we can throw a paramter~$n$ in there, for the number of FPs it must find.) Perhaps informally we say that a bloom filter is secure if, for ``reasonable'' $t,q_h,q_m$, the value of~$\epsilon$ is not ``significantly larger'' than the designer's target.  I guess that's not far off from one of your suggestions.}

%\jnote{One thing that is nice about the NY notion is that you get a ``clean'' definition of security: no matter how many FPs the attacker has found so far, the probability that it can output a fresh FP is still $\epsilon$.}


\begin{figure}
\centering
\fpage{.6}{
\hpagess{.6}{.35}
{
\experimentv{$\ExpFPSecHash{B,t}{\distr{U}{n},A}$}\\
$\calS \getsr \distr{U}{n}$\\
$h_1,\ldots,h_k \getsr \Hash$\\
$(M,\tau) \getsr \Rep^{\HashOracle}(\calS)$\\
$\calX \getsr A^{\QryOracle}(\calS)$\\
if $|\calX| < t$ or $\calX \cap \calS \neq \emptyset$ then \\
\nudge Ret 0\\
If $\exists x \in \calX$ s.t. $\Qry^{\HashOracle}(M,\tau,x)=0$ then\\
\nudge Ret 0\\
Ret 1
}
%
{
\oracle{$\QryOracle(x)$}\\
Ret $\Qry^{\HashOracle}(M,\tau,x)$\\

\medskip
\oracle{$\HashOracle(x)$}\\
Ret $\left(h_1(x),\ldots,h_k(x)\right)$\\
}
}
%%%%%%%
\fpage{.6}{
\hpagess{.6}{.35}
{
\experimentv{$\ExpFPPubHashBB{B,t}{\distr{U}{n}, A}$}\\
$\calS \getsr \distr{U}{n}$\\
$h_1,\ldots,h_k \getsr \Hash$\\
$(M,\tau) \getsr \Rep^{\HashOracle}(\calS)$\\
$\calX \getsr A^{\QryOracle,\HashOracle}(\calS)$\\
if $|\calX| < t$ or $\calX \cap \calS \neq \emptyset$ then \\
\nudge Ret 0\\
If $\exists x \in \calX$ s.t. $\Qry^{\HashOracle}(M,\tau,x)=0$ then\\
\nudge Ret 0\\
Ret 1
}
%
{
\oracle{$\QryOracle(x)$}\\
Ret $\Qry^{\HashOracle}(M,\tau,x)$\\

\medskip
\oracle{$\HashOracle(x)$}\\
Ret $\left(h_1(x),\ldots,h_k(x)\right)$\\
}
}
%%%%%%%
\fpage{.6}{
\hpagess{.6}{.35}
{
\experimentv{$\ExpFPPubHash{B,t}{\distr{U}{n}, A}$}\\
$\calS \getsr \distr{U}{n}$\\
$h_1,\ldots,h_k \getsr \Hash$\\
$(M,\tau) \gets \Rep^{\HashOracle}(\calS)$\\
$\calX \getsr A^{\QryOracle}(S,\{h_1,h_2,\ldots,h_k\})$\\
if $|\calX| < t$ or $\calX \cap \calS \neq \emptyset$ then \\
\nudge Ret 0\\
If $\exists x \in \calX$ s.t. $\Qry^{\HashOracle}(M,\tau,x)=0$ then\\
\nudge Ret 0\\
Ret 1 
}
%
{
\oracle{$\QryOracle(x)$}\\
Ret $\Qry^{\HashOracle}(M,\tau,x)$\\

\medskip
\oracle{$\HashOracle(x)$}\\
Ret $\left(h_1(x),\ldots,h_k(x)\right)$\\
} } \caption{False-positive security (soundness) for an
$(n,k,m)$-filter~$B$ with private hash functions (top), black-box
queriable hash functions (middle), and public hash functions
(bottom). \jnote{Could also consider not giving $\calS$ to the
adversary.} } \label{fig:fp-filter}
\end{figure}


%%%%
% \if{0}
% \begin{figure}
% \centering
% \fpage{.6}{
% \hpagess{.6}{.35}
% {
% \experimentv{$\ExpFPSecHash{S,B}{A}$}\\
% $ \{h_1,h_2,\ldots,h_k\} \getsr \Hash$\\
% $M \gets \Rep^{\HashOracle}(S)$\\
% $x \getsr A^{\QryOracle}(S)$\\
% if $x \not\in S \wedge \Qry^{\HashOracle}(M,x)=1$ then\\
% \nudge Ret 1\\
% Ret 0
% }
% %
% {
% \oracle{$\QryOracle(x)$}\\
% Ret $\Qry^{\HashOracle}(M,x)$\\

% \medskip
% \oracle{$\HashOracle(i,x)$}\\
% Ret $h_i(x)$\\
% }
% }
% %%%%%%%
% \fpage{.6}{
% \hpagess{.6}{.35}
% {
% \experimentv{$\ExpFPPubHashBB{S,B}{A}$}\\
% $ \{h_1,h_2,\ldots,h_k\} \getsr \Hash$\\
% $M \gets \Rep^{\HashOracle}(S)$\\
% $x \getsr A^{\QryOracle,\HashOracle}(S)$\\
% if $x \not\in S \wedge \Qry^{\HashOracle}(M,x)=1$ then\\
% \nudge Ret 1\\
% Ret 0
% }
% %
% {
% \oracle{$\QryOracle(x)$}\\
% Ret $\Qry^{\HashOracle}(M,x)$\\

% \medskip
% \oracle{$\HashOracle(i,x)$}\\
% Ret $h_i(x)$\\
% }
% }
% %%%%%%%
% \fpage{.6}{
% \hpagess{.6}{.35}
% {
% \experimentv{$\ExpFPPubHash{S,B}{A}$}\\
% $ \{h_1,h_2,\ldots,h_k\} \getsr \Hash$\\
% $M \gets \Rep^{\HashOracle}(S)$\\
% $x \getsr A^{\QryOracle}(S,\{h_1,h_2,\ldots,h_k\})$\\
% if $x \not\in S \wedge \Qry^{\HashOracle}(M,x)=1$ then\\
% \nudge Ret 1\\
% Ret 0
% }
% %
% {
% \oracle{$\QryOracle(x)$}\\
% Ret $\Qry^{\HashOracle}(M,x)$\\

% \medskip
% \oracle{$\HashOracle(i,x)$}\\
% Ret $h_i(x)$\\
% }
% }
% \caption{False-positive security (soundness) for an $(n,k,m)$-filter~$B$ with private hash functions (top), black-box queriable hash functions (middle), and public hash functions (bottom). }
% \label{fig:fp-filter}
% \end{figure}
%\fi
%%%%%



\heading{Privacy of hash-based filters.} We now define privacy notions for $(n,k,m)$-filters.  Informally, the adversary is given the representation~$M$ of a secret set~$\calS$, and its goal is to guess one of the elements of~$\calS$.  Of course, if the distribution~$\distr{U}{n}$ has low min-entropy with respect to any particular element $x \in U$, then it will be relatively easy to guess~$x$.  To capture this min-entropy, let $p_{\mathrm{max}} = \max_{x \in U} \Prob{\calS \getsr \distr{U}{n}:\, x \in \calS}$ and define $\mu = -\log_2 p_{\mathrm{max}}$ to be the (element-wise) min-entropy of distribution $\distr{U}{n}$.

\tsnote{Explain need for $\MemOracle$, as a way to disambiguate true positives from false positives.}

We note that~$\calS$ must be independent of the hash functions~$h_1,h_2,\ldots,h_k$ used to create the representation of~$\calS$.  \tsnote{I thought this would be needed, but now I'm not sure it is. }

A weaker notion of privacy would not give~$M$ to the adversary.  However, this would not capture attacks such as those mounted by Neidermayer et al.\cite{XXX}, and would not speak to settings in which (say) an honest-but-curious third party is given the representation~$M$ in order to carry out some task on behalf of the holder of~$\calS$.

\begin{figure}
\centering
\fpage{.6}{
\hpagess{.6}{.35}
{
\experimentv{$\ExpPrivSecHash{B}{\distr{U}{n}, A}$}\\
$\calS \getsr \distr{U}{n}$\\
$h_1,\ldots,h_k \getsr \Hash$\\
$(M,\tau) \getsr \Rep^{\HashOracle}(\calS)$\\
$x \getsr A^{\QryOracle}(M)$\\
if $x\in \calS$ then Ret 1\\
Ret 0
}
%
{
\oracle{$\MemOracle(x)$}\\
Ret $[x \in \calS]$\\

\medskip
\oracle{$\QryOracle(x)$}\\
Ret $\Qry^{\HashOracle}(M,\tau,x)$\\

\medskip
\oracle{$\HashOracle(x)$}\\
Ret $\left(h_1(x),\ldots,h_k(x)\right)$\\
}
}
%%%%%%%%%%
\fpage{.6}{
\hpagess{.6}{.35}
{
\experimentv{$\ExpPrivPubHashBB{B}{\distr{U}{n}, A}$}\\
$ \calS \getsr \distr{U}{n}$\\
$h_1,\ldots,h_k \getsr \Hash$\\
$(M,\tau) \getsr \Rep^{\HashOracle}(\calS)$\\
$x \getsr A^{\QryOracle,\HashOracle}(M)$\\
if $x\in \calS$ then Ret 1\\
Ret 0\\
}
%
{
\oracle{$\MemOracle(x)$}\\
Ret $[x \in \calS]$\\

\medskip
\oracle{$\QryOracle(x)$}\\
Ret $\Qry^{\HashOracle}(M,\tau,x)$\\

\medskip
\oracle{$\HashOracle(x)$}\\
Ret $\left(h_1(x),\ldots,h_k(x)\right)$\\
}
}
%%%%%%%
\fpage{.6}{
\hpagess{.6}{.35}
{
\experimentv{$\ExpPrivPubHash{B}{\distr{U}{n}, A}$}\\
$ \calS \getsr \distr{U}{n}$\\
$h_1,\ldots,h_k \getsr \Hash$\\
$(M,\tau) \getsr \Rep^{\HashOracle}(\calS)$\\
$x \getsr A^{\QryOracle}(M,\{h_1,h_2,\ldots,h_k\})$\\
if $x\in \calS$ then Ret 1\\
Ret 0\\
}
%
{
\oracle{$\MemOracle(x)$}\\
Ret $[x \in \calS]$\\

\medskip
\oracle{$\QryOracle(x)$}\\
Ret $\Qry^{\HashOracle}(M,\tau,x)$\\

\medskip
\oracle{$\HashOracle(x)$}\\
Ret $\left(h_1(x),\ldots,h_k(x)\right)$\\
}
}
\caption{Set-privacy for an $(n,k,m)$-filter~$B$ for private (top), black-box queriable (middle),  and public (bottom) hash functions. \textcolor{cyan}{Revisit when the FP notion settles out.}}
\label{fig:fp-filter}
\end{figure}
